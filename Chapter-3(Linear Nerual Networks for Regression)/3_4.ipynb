{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "Ri6uMGPUJuxi"
      ],
      "authorship_tag": "ABX9TyOwSiocvInUTrAdqTLCGV3w",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arnav39/d2el-en/blob/main/3_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3.4 Linear Regression from scratch"
      ],
      "metadata": {
        "id": "ZGXiovf38CMX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DN8j6UwD79mM"
      },
      "outputs": [],
      "source": [
        "!pip install matplotlib_inline\n",
        "!pip install --upgrade d2l==1.0.0a0"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "help(torch.normal)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wl4dgpR0-gA7",
        "outputId": "2864520b-5624-4e6c-b599-34ad28b5b626"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Help on built-in function normal in module torch:\n",
            "\n",
            "normal(...)\n",
            "    normal(mean, std, *, generator=None, out=None) -> Tensor\n",
            "    \n",
            "    Returns a tensor of random numbers drawn from separate normal distributions\n",
            "    whose mean and standard deviation are given.\n",
            "    \n",
            "    The :attr:`mean` is a tensor with the mean of\n",
            "    each output element's normal distribution\n",
            "    \n",
            "    The :attr:`std` is a tensor with the standard deviation of\n",
            "    each output element's normal distribution\n",
            "    \n",
            "    The shapes of :attr:`mean` and :attr:`std` don't need to match, but the\n",
            "    total number of elements in each tensor need to be the same.\n",
            "    \n",
            "    .. note:: When the shapes do not match, the shape of :attr:`mean`\n",
            "              is used as the shape for the returned output tensor\n",
            "    \n",
            "    .. note:: When :attr:`std` is a CUDA tensor, this function synchronizes\n",
            "              its device with the CPU.\n",
            "    \n",
            "    Args:\n",
            "        mean (Tensor): the tensor of per-element means\n",
            "        std (Tensor): the tensor of per-element standard deviations\n",
            "    \n",
            "    Keyword args:\n",
            "        generator (:class:`torch.Generator`, optional): a pseudorandom number generator for sampling\n",
            "        out (Tensor, optional): the output tensor.\n",
            "    \n",
            "    Example::\n",
            "    \n",
            "        >>> torch.normal(mean=torch.arange(1., 11.), std=torch.arange(1, 0, -0.1))\n",
            "        tensor([  1.0425,   3.5672,   2.7969,   4.2925,   4.7229,   6.2134,\n",
            "                  8.0505,   8.1408,   9.0563,  10.0566])\n",
            "    \n",
            "    .. function:: normal(mean=0.0, std, *, out=None) -> Tensor\n",
            "       :noindex:\n",
            "    \n",
            "    Similar to the function above, but the means are shared among all drawn\n",
            "    elements.\n",
            "    \n",
            "    Args:\n",
            "        mean (float, optional): the mean for all distributions\n",
            "        std (Tensor): the tensor of per-element standard deviations\n",
            "    \n",
            "    Keyword args:\n",
            "        out (Tensor, optional): the output tensor.\n",
            "    \n",
            "    Example::\n",
            "    \n",
            "        >>> torch.normal(mean=0.5, std=torch.arange(1., 6.))\n",
            "        tensor([-1.2793, -1.0732, -2.0687,  5.1177, -1.2303])\n",
            "    \n",
            "    .. function:: normal(mean, std=1.0, *, out=None) -> Tensor\n",
            "       :noindex:\n",
            "    \n",
            "    Similar to the function above, but the standard deviations are shared among\n",
            "    all drawn elements.\n",
            "    \n",
            "    Args:\n",
            "        mean (Tensor): the tensor of per-element means\n",
            "        std (float, optional): the standard deviation for all distributions\n",
            "    \n",
            "    Keyword args:\n",
            "        out (Tensor, optional): the output tensor\n",
            "    \n",
            "    Example::\n",
            "    \n",
            "        >>> torch.normal(mean=torch.arange(1., 6.))\n",
            "        tensor([ 1.1552,  2.6148,  2.6535,  5.8318,  4.2361])\n",
            "    \n",
            "    .. function:: normal(mean, std, size, *, out=None) -> Tensor\n",
            "       :noindex:\n",
            "    \n",
            "    Similar to the function above, but the means and standard deviations are shared\n",
            "    among all drawn elements. The resulting tensor has size given by :attr:`size`.\n",
            "    \n",
            "    Args:\n",
            "        mean (float): the mean for all distributions\n",
            "        std (float): the standard deviation for all distributions\n",
            "        size (int...): a sequence of integers defining the shape of the output tensor.\n",
            "    \n",
            "    Keyword args:\n",
            "        out (Tensor, optional): the output tensor.\n",
            "    \n",
            "    Example::\n",
            "    \n",
            "        >>> torch.normal(2, 3, size=(1, 4))\n",
            "        tensor([[-1.3987, -1.9544,  3.6048,  0.7909]])\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.normal(0, 1, (2, 3))\n",
        "# mean = 0\n",
        "# std_dev = 1\n",
        "# size = (2, 3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZwmBuNu3-vgy",
        "outputId": "ba2471db-fbfc-4957-fc48-659aadfab3f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-2.2378,  0.3761,  0.1021],\n",
              "        [ 1.2296, -0.7625, -1.3092]])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import torch\n",
        "from d2l import torch as d2l"
      ],
      "metadata": {
        "id": "OC8bWthQ8WUc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LinearRegressionScratch(d2l.Module):\n",
        "\n",
        "  def __init__(self, num_inputs, lr, sigma=0.01):\n",
        "    super().__init__()\n",
        "    self.save_hyperparameters() # saves function arguments into class's attributes\n",
        "    self.w = torch.normal(0, sigma, (num_inputs, 1), requires_grad=True)\n",
        "    self.b = torch.zeros(1, requires_grad=True)"
      ],
      "metadata": {
        "id": "jgPYnWnn8ffP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.rand(5, 1)\n",
        "b = torch.rand(1, 1, requires_grad=True)\n",
        "c = torch.randn(1, requires_grad=True)\n",
        "\n",
        "d = torch.mm(a, b) + c\n",
        "print(f\"d.shape = {d.shape}\")\n",
        "print(f\"d = {d}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Go8-3bMMBNJW",
        "outputId": "06767977-5e41-4ff0-8acb-acf9601141da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "d.shape = torch.Size([5, 1])\n",
            "d = tensor([[2.4605],\n",
            "        [2.4482],\n",
            "        [2.4691],\n",
            "        [2.4820],\n",
            "        [2.5713]], grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def add_to_class(Class):\n",
        "  def wrapper(obj):\n",
        "    setattr(Class, obj.__name__, obj)\n",
        "  return wrapper"
      ],
      "metadata": {
        "id": "o66zB8P7_qTB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@add_to_class(LinearRegressionScratch)\n",
        "def forward(self, X):\n",
        "  return torch.matmul(X, self.w) + self.b"
      ],
      "metadata": {
        "id": "2kHK1Bri_KIu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@add_to_class(LinearRegressionScratch)\n",
        "def loss(self, y_hat, y):\n",
        "  l = (y_hat - y.reshape(y_hat.shape)) ** 2 / 2\n",
        "  return l.mean()"
      ],
      "metadata": {
        "id": "yqUc73w8AWv5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# optimizer\n",
        "\n",
        "class SGD(d2l.HyperParameters):\n",
        "\n",
        "  def __init__(self, params, lr):\n",
        "    self.save_hyperparameters()\n",
        "\n",
        "  def step(self):\n",
        "    for param in self.params:\n",
        "      param -= self.lr * param.grad\n",
        "\n",
        "  def zero_grad(self):\n",
        "    for param in self.params:\n",
        "      if param.grad is not None:\n",
        "        param.grad_zero_()"
      ],
      "metadata": {
        "id": "tOorl964CNO5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@add_to_class(LinearRegressionScratch)\n",
        "def configure_optimizer(self):\n",
        "  return SGD([self.w, self.b], self.lr)"
      ],
      "metadata": {
        "id": "8YDb91IGEIGF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = LinearRegressionScratch(2, lr=0.03)\n",
        "data = d2l.SyntheticRegressionData(w = torch.tensor([2, -3.4]), b = 4.2)\n",
        "trainer = d2l.Trainer(max_epochs=3)"
      ],
      "metadata": {
        "id": "ufEn8cxcFlkc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.w"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B7rPu3ilJCDS",
        "outputId": "877e2047-fc90-45d8-b945-1685e958aff7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-1.1922e-05],\n",
              "        [-4.4621e-03]], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "d2l.Trainer.fit??"
      ],
      "metadata": {
        "id": "E4kV7zPYJH2L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.fit(model, data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "id": "4G1ZzWExGAqd",
        "outputId": "a8f7c02a-244d-4c3d-ab3d-b9c6d3fbcb08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-60-099f36836577>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/d2l/torch.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, data)\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 269\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfigure_optimizers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    270\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_batch_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/d2l/torch.py\u001b[0m in \u001b[0;36mconfigure_optimizers\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    217\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mconfigure_optimizers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m         \u001b[0;34m\"\"\"Defined in :numref:`sec_classification`\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 219\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/optim/sgd.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, params, lr, momentum, dampening, weight_decay, nesterov, maximize, foreach)\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnesterov\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmomentum\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mdampening\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Nesterov momentum requires a momentum and zero dampening\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setstate__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, params, defaults)\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mparam_groups\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam_groups\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"optimizer got an empty parameter list\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam_groups\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mparam_groups\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'params'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mparam_groups\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: optimizer got an empty parameter list"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ex 3.4"
      ],
      "metadata": {
        "id": "Ri6uMGPUJuxi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Q1\n",
        "\n",
        "when we initialise the weights to zero, the model is not able to learn anything when we use nn.Linear model"
      ],
      "metadata": {
        "id": "sFmF9xAXK3Cx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from sklearn import datasets\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "z6wFw5HSG-9w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_numpy, y_numpy = datasets.make_regression(n_samples=1000, n_features=5, noise=20, random_state=1)\n",
        "\n",
        "X = torch.from_numpy(X_numpy.astype(np.float32))\n",
        "y = torch.from_numpy(y_numpy.astype(np.float32)).reshape(-1, 1)"
      ],
      "metadata": {
        "id": "GX1TfZbgLDTB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"X.shape = {X.shape}\")\n",
        "print(f\"y.shape = {y.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LJswQP3yNsDD",
        "outputId": "d858d67d-2b12-4937-9ca0-6ad2b4644e0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X.shape = torch.Size([1000, 5])\n",
            "y.shape = torch.Size([1000, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "forward pass : y_hat and loss\n",
        "\n",
        "backward pass : grad\n",
        "\n",
        "update : params"
      ],
      "metadata": {
        "id": "WqgKrCowNzSF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.randn(100, 1)\n",
        "b = torch.randn(100, 1)\n",
        "\n",
        "c = nn.MSELoss()\n",
        "c(a, b).item()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vpRwNrJaOvcj",
        "outputId": "8cbf01d8-4f1d-4fbb-d0d4-254cbb27a1b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.8610917329788208"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.rand(100, 5)\n",
        "b = torch.rand(5, 1)\n",
        "\n",
        "c = torch.mm(a, b)\n",
        "print(c.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EfJThzazQZhi",
        "outputId": "09671c8e-5fb1-4760-cc02-7fcb4789b2ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([100, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.zeros((5, 1), dtype=torch.float32, requires_grad=True)\n",
        "print(a.shape)\n",
        "print(a)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gqa_l2NHQw1D",
        "outputId": "00fdd2bf-20aa-4ff1-f3cd-42a307c58bb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([5, 1])\n",
            "tensor([[0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.]], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.rand(100, 5)\n",
        "b = torch.zeros(5, 1)\n",
        "\n",
        "print(f\"a.shape = {a.shape}\")\n",
        "print(f\"b.shape = {b.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VkuLD4jyRxZ-",
        "outputId": "b4d40125-2c0b-41a0-c6b5-674aeeee4c35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a.shape = torch.Size([100, 5])\n",
            "b.shape = torch.Size([5, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "c = torch.mm(a, b)\n",
        "c.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D1ThdIkqSJwp",
        "outputId": "fc0d478d-0e23-4368-91fb-df2e91ec83c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([100, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "d = [b]\n",
        "d"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uU7bfFf_Sba6",
        "outputId": "e38e183d-6419-47f6-dca7-af95479272d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor([[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]])]"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Not using nn.Linear : the weights are able to learn"
      ],
      "metadata": {
        "id": "KRamymo3Xdvr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "w = torch.zeros(X.shape[1], 1, requires_grad=True)\n",
        "\n",
        "max_epochs = 100\n",
        "learning_rate = 0.07\n",
        "\n",
        "loss = nn.MSELoss()\n",
        "optimizer = torch.optim.SGD([w], lr=learning_rate)\n",
        "\n",
        "for epoch in range(max_epochs):\n",
        "\n",
        "  # forward pass\n",
        "  y_hat = torch.mm(X, w)\n",
        "  l = loss(y, y_hat)\n",
        "\n",
        "  # backward pass\n",
        "  l.backward()\n",
        "\n",
        "  # update params\n",
        "  optimizer.step()\n",
        "\n",
        "  # zero the grad\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "  if (epoch+1)%10 == 0:\n",
        "    print(f\"epoch {epoch+1}/{max_epochs}, w = {w}, loss = {l}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cUpwMsoaXM2R",
        "outputId": "73734091-8c4d-4232-84a1-a36d7ee5ca37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 10/100, w = tensor([[54.5013],\n",
            "        [ 5.2077],\n",
            "        [ 5.4963],\n",
            "        [26.9403],\n",
            "        [23.8573]], requires_grad=True), loss = 932.4965209960938\n",
            "epoch 20/100, w = tensor([[68.0343],\n",
            "        [ 7.2285],\n",
            "        [ 6.4760],\n",
            "        [31.9780],\n",
            "        [29.3999]], requires_grad=True), loss = 428.60595703125\n",
            "epoch 30/100, w = tensor([[71.4157],\n",
            "        [ 7.8356],\n",
            "        [ 6.6342],\n",
            "        [32.9059],\n",
            "        [30.6978]], requires_grad=True), loss = 399.1352844238281\n",
            "epoch 40/100, w = tensor([[72.2644],\n",
            "        [ 7.9995],\n",
            "        [ 6.6559],\n",
            "        [33.0716],\n",
            "        [31.0045]], requires_grad=True), loss = 397.36029052734375\n",
            "epoch 50/100, w = tensor([[72.4782],\n",
            "        [ 8.0413],\n",
            "        [ 6.6579],\n",
            "        [33.0994],\n",
            "        [31.0776]], requires_grad=True), loss = 397.25115966796875\n",
            "epoch 60/100, w = tensor([[72.5322],\n",
            "        [ 8.0515],\n",
            "        [ 6.6578],\n",
            "        [33.1035],\n",
            "        [31.0951]], requires_grad=True), loss = 397.244384765625\n",
            "epoch 70/100, w = tensor([[72.5458],\n",
            "        [ 8.0539],\n",
            "        [ 6.6577],\n",
            "        [33.1039],\n",
            "        [31.0994]], requires_grad=True), loss = 397.2439270019531\n",
            "epoch 80/100, w = tensor([[72.5493],\n",
            "        [ 8.0545],\n",
            "        [ 6.6576],\n",
            "        [33.1039],\n",
            "        [31.1004]], requires_grad=True), loss = 397.243896484375\n",
            "epoch 90/100, w = tensor([[72.5502],\n",
            "        [ 8.0546],\n",
            "        [ 6.6576],\n",
            "        [33.1039],\n",
            "        [31.1007]], requires_grad=True), loss = 397.243896484375\n",
            "epoch 100/100, w = tensor([[72.5504],\n",
            "        [ 8.0546],\n",
            "        [ 6.6576],\n",
            "        [33.1038],\n",
            "        [31.1008]], requires_grad=True), loss = 397.2438659667969\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using torch only: weights are not able to learn"
      ],
      "metadata": {
        "id": "Dj_DX2D3XQIq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "w = torch.zeros(X.shape[1], 1, requires_grad=True)\n",
        "\n",
        "max_epochs = 10\n",
        "learning_rate = 0.07\n",
        "n_samples, n_features = X.shape\n",
        "input_size=n_features\n",
        "output_size=1\n",
        "\n",
        "model = nn.Linear(input_size, output_size)\n",
        "loss = nn.MSELoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "for epoch in range(max_epochs):\n",
        "\n",
        "  # forward pass\n",
        "  y_hat = model(X)\n",
        "  l = loss(y, y_hat)\n",
        "\n",
        "  # backward pass\n",
        "  l.backward()\n",
        "\n",
        "  # update params\n",
        "  optimizer.step()\n",
        "\n",
        "  # zero the grad\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "  if (epoch+1)%1 == 0:\n",
        "    print(f\"epoch {epoch+1}/{max_epochs}, loss = {l}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YbEcfNUnONU4",
        "outputId": "f75ce8f1-f27e-4d03-b26a-ae71bb5e6fde"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1/10, loss = 7565.421875\n",
            "epoch 2/10, loss = 5762.1455078125\n",
            "epoch 3/10, loss = 4414.8525390625\n",
            "epoch 4/10, loss = 3407.599365234375\n",
            "epoch 5/10, loss = 2654.09716796875\n",
            "epoch 6/10, loss = 2090.081787109375\n",
            "epoch 7/10, loss = 1667.656982421875\n",
            "epoch 8/10, loss = 1351.0985107421875\n",
            "epoch 9/10, loss = 1113.7457275390625\n",
            "epoch 10/10, loss = 935.6865844726562\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model(X).detach().numpy()\n",
        "\n",
        "plt.plot(X_numpy, y_numpy, 'ro')\n",
        "plt.plot(X_numpy, predictions, 'b');"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "hQIoeED8OS_2",
        "outputId": "1f0a6be9-66e7-48df-8fb7-3bcebddd9407"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAD4CAYAAAAEhuazAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOydd3hUxfrHP2c3vUAgJBBKQpUugqiAKHaK/dr12hV7v4rotVyvBb323svPYO+K2FEEbCBFQHrvJbT0st/fH7M9u8km2RTgfJ/nfXbPOXPmzCnznXfeeecdSxI2bNiwYWPvgqOxC2DDhg0bNhoeNvnbsGHDxl4Im/xt2LBhYy+ETf42bNiwsRfCJn8bNmzY2AsR09gFiAStWrVSx44dG7sYNmzYsLFbYcaMGVskZYQ6tluQf8eOHZk+fXpjF8OGDRs2ditYlrUy3DHb7GPDhg0beyFs8rdhw4aNvRA2+duwYcPGXgib/G3YsGFjL4RN/jZs2LCxF8Im/70J48dDx47gcJjf8eMbu0S1w55wHw15D3vC89rT0BTeiaQmL/vvv79s1BG5uVJSkgQ+SUoy+0OlzcmRLMv8hkrTWKjJfdQm7/R0X77p6dG9d89zBfNs6+MeQl2zvp6Xjdoh0ncShXoITFcYXm10Yo9EbPKPAjykEyw5OYHpmjpZRHofNUVurhQXVznf2NjoNSzBzzXa9xAK9fW8bNQekbyTKNXDqsjfMsebNgYOHCh7klcd4XCYTygYlgUul2+7Y0dYGWJeSE4OrFhRX6WLHJHeR00R7r4hOvdeVf4e1PUeQqG+npeN2iOSdxKlemhZ1gxJA0MWI+JcbOzeyM6ObP+qVaHThdvf0Ij0PmqKqu4vGvceSR51vYea5Fkf17IRGSJ5Jw1QD23y31tw332QlBS4LynJ7PdHUyeLSO+jpqjq/qJx79XlEY17CIX6el42ao9I3klD1MNw9qCmJLbNP0qIZACpqdv8pfoZkG4Mm79n0Le+B9Wb8gD+3orq3kkD2PwbndgjEZv8Gxh7K1k0lLfP3vZcbdQO9eztYw/42rBhw8YeCnvA14YNGzZsBMAmfxs2bNjYC2GTvw0bNmzshagz+VuWlWBZ1u+WZc22LGueZVn/ce/vZFnWb5ZlLbEs613LsuLc++Pd20vcxzvWtQw2bNiwYaNmiIbmXwIcIakfsB8wwrKsQcCDwGOSugLbgIvd6S8Gtrn3P+ZOZ8OGDRs2GhB1Jn+3R1G+ezPWLQKOAD5w738DOMn9/0T3Nu7jR1qWZdW1HDb2QNiRL+uGxrin+rjmnvhumgLC+YDWRAAnMAvIx2jyrYAlfsc7AHPd/+cC7f2OLQVahchzNDAdmJ6dnV1j/1YbuzkacrLZ7jCxraZojHuqj2vuie+mAUFDTfIC0oBJwNC6kr+/2JO8diNEayJTQ0ajbMhrBT+fK66on4lfjRHNMxrX9A977XSGzs+OShoxGoz8zbW4E7gZ2ALEuPcNBr52//8aGOz+H+NOZ1WVp03+uwmiqaUFx7v3D4kQbTTUtSIJ6xwtrbYhn1+0rhnJ82mI+9iDUBX5R8PbJ8OyrDT3/0TgaOBvdw/gVHey84FP3f8/c2/jPv6Du5A2dnfcfjsUFgbuKyw0+2uKhgww11DXCvV8glHb5xWMxgjQV9drRvJ8apqnjbCIhrdPFjDJsqw5wB/At5K+AMYAN1qWtQRIB15xp38FSHfvvxG4NQplsNEUEM0wtA0ZjbKhrhXpc4hG2N7GiOZZ12tGet92VNLoIFyXoCmJbfbZTRBtO3NDBkJriGuFez71Zc9ujEBydblmJM/HDohXI2BH9bTRILA9M6pGQ9r8d0dU9Xz25udSB1RF/nZ4BxvRwznnwIsvmqXmLMv8vvii2W8j9PO54gr7eXng/3wAnE7zu7c/l3qCHdLZhg0bNvZQ2CGdbdioC5rSDNOGKktdrtMQZWxK72R3RTh7UFMS2+Zvo9HQlMYxGqosdblOQ5SxKb2TJg7sAV8btcbevvSg/7KO/uJ0+p5FQz2jhpq1W5frNEQZI7nG3v7dumGTv43aobHiwzREpQ11nVChF6rzzLniioZ7Rg01a7cu16nLuZG++3DX8FwnPV2KjW3Y77aJwiZ/G7VDQ8eHaUyzRmysFBdXmUiq8zsPF39md45B1Biaf03efaTzJRrqu23CsMnfRu3Q0PFhGpvcoin18Yz2ZJt/Td59TWIANcR324Rhk7+N2qGhNf/GNmvURhpS85ca1yxWn+fW9N37X8PW/MPCJn8btUN9a5rBJBFucLUxNf+qyCUSm399kfXulm9116pLIxrJ+7Rt/jb57+149VVpwoQanFCfJBOJ3T1EpS0slO65R9q4sQGu7R9vPz3dSPCzCPeMqmk8d+2S7rjD3E+dy18FuW3aZK6zfXt0860TohnqIlRecXGh31UTwc8/SwccIM2aVb/XscnfhhddukgxMdLXXzdyQcJpa+np1TY2//ufSTptWh2uH4m3T10Joxqz2Q8/mM333otuvv7Ytk3abz9zeOnS6OVbZ4S7ltPZcKamRsC77wbe7jvv1O/1bPK34YWnziUnS7//Xo8Xqq4y1tK+v3271LKl1KGDVFFRb6WPDqoyGclofSBdeWUN8szNDZ9n0LPLz5eGDDGHjj++DuWt6ZhLqNW4gr+BxlhsppHgcvkUFn+ZOrX+r22Tvw0v2reXRoyQOnWSWrWSFi6sh4tEYj6opZZ5550m2dix9VDuaCPcPVqWlJur1avNZu/eEeZXnanE79kVF0tHH+079OuvdShvTZdhjCQyZ2MsM9nAKC+vPFXE6ZQWLWq4Mtjkb8OLtm2liy82H2BGhqlra9dG+SKRzsCsoX150yYpJcUknT8/ymWuD+Tmhtdwc3JUWOjb3Lw5gvyqGtj0e3ZlZdLJJ/sOHXlkDcpbV5t/dYOvnm9gDw7RUFBgFCz/W+vSpQ5jVHWATf42vGjdWho92vyfPt2Q6b77Gttw1BBpl76GdtrrrzfZDBwYxbLWN6ox0Xj478MPI8irKjOS+9lVVEjnnWd29eplfr//vgblravtvDrXS/9vYDex00eKTZuk7t0Db/eoo4z5rbFgk78NL1q1Ml1RD775xji6HHqoVFTk23/NNXUwrdRDl37lSp8zzpMt7qw3wpg+XercWerTR1q/PgoZBj2L8ZylwUyVKzlFyslRB1YKpGuO+bvGeQU/V5dLuvpqs+vOO6WOHaVBg8z+OiM3N9AVNz29drNv9yCzjgcLF1Z2FBs92vTAaguXy3jlHXWUdPvttc/HJn8bXrRoYQjCH2+/bb6Ek082dkpJOvFEs69WXkH10KW/+GKTTQyl2kSrqOUbjOOPN9k6HNKWLVHIMDfXywzfc7hiKFU3FsrlLn9/Zgikfa051d9HNc/1ttvMrptukt54w/z//PPo3kOAxMZWLvNetBrXlCmVb/H+++vW2JaVmUfUt6/JLytL+uyz2udnk78NL5o1k667rvL+J57waSz+3gnZ2dKOHbW4UBS79AsWGDIG6Xg+rVzjoqRNTp3qs1qkpERJY5ak9HTNp4fSyBNIz3GZt+xH8Y2xhlChrVaYeQT+CPNcH3zQZHnppaYB79HDmPPqdA/+XjuRavLBPQTPi/MEytsDzDzvv1/5Mbz5Zt3yLCiQnnzS97izskydrPEckCDY5G/Di+Rk6YYbQh8bO9Z8EXfdZbxDPB/2ZZc1aBEr4fTTfWV5n1Mq17wouAf++advMNkj06f7jpeVSXPm1C7vjWSqE0uNtYTNKiDRe5EzeNt7vU84IbAAYTTlzZulFSt82889Z5KfcYYh/g8+MNt18iHPzdX2xDZawD5Vk3+wDT8pSS7QHPqY3o3nHqLcGywvN+8sag10NaiokB59tPLtf/dd3fLdskX6z3987WW0SN8Dm/xteJGYKP3rX6GPuVzSRReZr+Lpp03d9GjCNfnIV6yIngfRjBm+ipbm2K4i4ivXwEg1/zBa89y5ZiwkJcUoqrGxUny8GfeQzHPxDKJu2xY+n1AoLJQGxc3wFvUO/qOFdFMF5sFexVNKJF/xFOoGHqn23lwu6aCDjFlAksaPN8U47jiptNQc75+zVfvELFE5zlpNYCsvl15qeYtasUltWeM1UVWr+bvV1rHcJ5Bm0s+XpgbjQDt2SIsXG2041MS0336T9t/fnB7gNlkPA8jFxaanHFzs2bPrlu/KlSZfT3sYbdL3wCZ/G17ExUljxoQ/XlZmiMSyzKBn9+7SPvuYurRzZ/X5z5plTEsxMYYwa6stezBypC80+2VHLIp6tMlFD3+qNm2MF1Tr1lJCgnTSSaa3kZ4ulZRI48aZ5K1aSa43I9dgKyqk006TLMulttZaxVOk/3GjQJrASAl0Cw8IXGrDWvVnhiqxTFCv5qOPzO64OOnjj43f+OGH+0jjy5t/EEivcoEvj7i4iOPbT53qI9ZYSvQZx4Un/mCbv2VpHLcIpBP4xNdoWFZEHmBbt5peZ1qaGZvKyZEyM32T+bZsMWYty5JSU02okureb20bgB07fONeHmnfXlq1qlbZeTF3rqkXMTH1S/oe1Cv5Ax2AScB8YB5wnXt/S+BbYLH7t4V7vwU8CSwB5gADqruGTf7Rg9NpBgarQkGBmRnqmZw5YYKpcNXNRF2+3HzM7dubQWVPXRw50oQyqGkXffJkc37v3uZ3yhQZu7GnYE5noOtSVQiheS4nRx2ca9SqlW/QG8z/CRPM/1tv9fHWCSeEziecBnvrrebQmDFSQmyZjkqYLAfl6swSFZIgga7lMXcWLkGFttE8dL65uSrP7qRezPUeio+XDjzQ1yi7XNLB8b+rAytVQmzocoYqd26u1q6V/vlPP16vjvhDePs81/I2gdSRZcojLfAaVTy3jRvNM0pNNbtatjS/2dnSpEmG/F96yWcaOfJIozlX937DvZeqsG6dGSvxz+KQQ0zDVBdMmeJzJmgI0vegvsk/y0PgQCqwCOgFPATc6t5/K/Cg+/8oYKK7ERgE/FbdNWzyjx7ABPmqDlu3+urT00/7fOwnTQqdfvNm00NISzPajSePe+812hsY//x3343MBc7lkg4+2ExE69nTzEiuidZdCUGa5xraqjNLlEae/vxTuvlmY/JJSDB+2WVlhmycTnNtMIOqkc5heOkls/uyy0wQOpDiYsoE0kSGe8+7kJcFUgKFAulTf8INspe/wbkC6UQ+EkidMnYGkNJPP5nTnuIqbx5TGKL1tA5L4sXEaVzsv5UcX+oj/ljp0xsm1ehZG/OTS3EU621O10K6hbyHgHeQ0EXXDf9bie4hkJQUX5ILLzTa94wZvthEiYnSM8+ECetRx3AR8+ebHqv/qeedZxSh2qKiwnhbDR3a8KTvQYOafYBPgaOBhUCWfA3EQvf/F4Cz/NJ704UTm/yjg4oK88bvuiuy9AsWmPTJydK8eWaWYufOlSet5OcbO3RCgolWGIzCQun556Vubj7o3NlU4oCKFRQPZgIjjfaXvstLDNelvqJfObCyDbqGYX83kKnu/K0UdurXNifK5TKNDBgLSX6+tGGDTxN9+GHz+/PPikjD/OYb02gMH24id7Zs6evmn0ZgZK/j+FQg/YuHBNII51e+4ykpXnW3hFh1ZJl6ME/N2C6QHk28LcDGfUzftWrt2OTtVfxFbzkp00W8HLLMXzBKXVkkkA6Ln6aMDEP8n3wS9E6qimgq44ro6Ywd1XudLCp0Hq9Xtru781tGJ12Wkqu4mHKBaXTbtzfnZ2Ya09aXX0oDBgQWeeLEyN5vTb6Nyf/+utIpd9xhxk9qi9JS42rr6bE2Bul70GDkD3QEVgHNgO1++y3PNvAFMNTv2PfAwBB5jQamA9Ozs7Pr+xntFSgtNW/8nnsiP6dvX0NcXbsaUgDp2msD8xw1ylTgjz+uOq/yclOxDzrI5NOqlXT33dLm594P0AorsNSPmerMErW3VgsMkcZRbBoPlujf3KP59FDE2p1b89xKC/VlthIp0E/xR6v09fE666zAyv/II9LgwaYxAzPRJjbWXXHDrevrNj/NnWs0yL59jebqccEEKYWdWkPbgPMGMF1gnl1qQqliKNV2mlXK/2muFEhp5Kk9q2RRrn9zj/f47wwUSA8O+sjrcXMYxv7flUUBeS1gH41kgkDqzt96j1M1iGmKifEj/hDPLlQvYNIkY34Cn+bco4dpPIOxcKF0/vmBofs7dfJNITjwQDNGEux1lZhoPJgieb+hyhgMl6tydE0wLrgVicm1HifIz5cef9yYqxqb9D1oEPIHUoAZwD/c29uDjm9TDcjfX2zNPzooLjZv/L77Ij/nppsM+ScmGrPNZW4X9cmTTSW68EKz/fzzkefpcpnzPTbQRKtQV/K0ltBZAr3NGQIpl7OVSIGaWyYQ/bYOffUqF+hovpYDozX2Y6YeTLvf2ICr8fbY/uK7Ghg3S3EU65vMc7Tp2fc1bJivoibHl2pw7O9KwvQ2Prj2J/Xvb8jooIPcmVShYa5fbw63aSOtfPwjbW7Xz9tggfR4i7sDznGBmrNNYAYvL055S+DSVTwVkC6fJLVio+IpUgYb9Tfd1ZFlOoc3vWlO4iOlkacdjjTpiiv0TsrFAmlfZgmk9bTWDlJ1Mw8qlhI1Y7se4QZtoaUhfkrDN95h7vn3NsdXIuquXSt7es2ZI515ZqBlJjPTPCcwjYGnQfD0kDzSl9la3u7gyAf1q3j/paWh3TU/4YTA3mQNxwk2bza9ac9YRVMgfQ/qnfyBWOBr4Ea/fbbZp4mhoMC88XHjIjwhN1efZFxizkm7X05HhY44woQN6NrVNw4QqRkpFObNky7iFcVSIgflOpkPBdI+/K3fOEAg9WSetzwe7W49rfUE1+ggx2/eCneI42c9y+XajHtkMGjhlCFDDLl89pmxJXvmH2VlSTGOCp3rHK/zeE0g/YMPpKQkPXyW0czPP99d4DC25QKSdMAB5pLT//ulChLT1YN53iT7WbNUdtlVAV43a2jrPf7QQ9K3HCWQHJRrLr286W7jv/L0HP7EGMAP53sNZqoEmksvgXQnpnHJj01Te1apPzM0hSEC6SqeVBvWCaSLeFkbyNQOUjWYqYqhVB9d92P4lxTinufSy2t+8tfi/b1h/vhDOmn/VSHbSn/p0sUoFp734ZEbeMQ3cG1Z1Q7u5+WFdjHetUu68cbK153CwaELFOE4wYoVphfs3+FoKqTvQX0P+FrA/wGPB+3/X9CA70Pu/8cGDfj+Xt01bPKPDnbuNG/8f/+LILGbaLfQUiDdx1i9FjdaIB1xhO9j98wIrhNycrSWLI3hgYA62BpjPx6GHzGF0O6WLJHuTXtIPd1kG0OpRvGFcjlbuzr0VGGhKbPDYRZOedOnMHttzSCN5V73f5eyWaYKLH2ZcZ7AuP15yhpMFhVYOjlxoizLmE3KsjvrOD4TuOSkTFChXznQ2Mz9wiR8xTGmvM5yjRkj5bfsICelSqBQR/CdXKBl5MhBmZyUaSqDvedezEtqzXoJdA5vKpld2kJLd2Nxr5vchmgqg7y9pIP4Rb9xgATaSYqGMEUxlOrD636q9v343+98uiuFnQGPoUMH4+0lGc+W4KiWweJwSKecIj32mCHMgGOUh/Y0cofCDsaqVWbiYnKyMR15sHGjdOqpgVlkZBiFI9y7VASa/5w5xjPK33zV1Ejfg/om/6GA3G6bs9wyCkh3m3QWA98BLeVrLJ4BlgJ/VWfykU3+UcO2beaNP/poBIn9KkYv5moEX0qgcWmBBP1TNbwREdwNTSEJSmVHpbrYi7kqadnGtyNUUDHLkgs0i301hgeUzQqB3ORrTnvxxcoaoDecAzsUQ4lASqBAIL3LqXqUG0xD1Nod9yiEbflfMcZd87HH3BPleMWXPxW6nGdDksz/uMnk7dioSy6RlJ6uIUxRR/ds4Nc4X20xYx7Pc2nAufcxViDNobcclOtfPCSBFtNFcRTrVN7VRW5PoliK1dHdmPkTv5MyfXBtBC/Q756/4mjFup+Th8TbJm/TYqubvuMIHcakKkkfpP1jZ+vj63/U4fFTKx1LSpImMzT8yX7EPH++dMEFPlNRnz5m1u/SpWaJRP/TDjwwhHtoDccJJk+Wjj02MHlTJX0PGtTbpz7EJv/oYMsW88YffzyCxH5d/ct4Ts3YrnIc+oHDvN3z5GTj3hmVDz83V49Yhgxf4uJKdb49q/QwN2oHbhec4AlGQVpcBZYmMSwgDw9JtHLHhbvMF2JHcW5Cu5QXNJHhpmKzRqckTvC6qn71la+snt6Hx7f9qqsMQdx+u5uImCMH5WrFxkCfdz85j9eVxVr1YY5OOsk887HcJyel2ocF3qRD+cl3nsMhJSd7x0VO5V3FU6R1mMZxFF8oniKlsEOxlOhmHtTNPCgH5dpJinY6mutgfo6c+N0oef0t/Sv1eZn5CL7n2Tpxu57mirBcbVGhFHeDHkOpxvCAbuRhxVBaKe2grpuMJ1lV8YQsS7/8Yibi+T+SsWOlX37xvVuPnHaaCbVc1XdX1ThBRYX06afGASCY9J98sumSvgc2+duQZCoBSE89FUFivwqYy9kC6Q3OVTNrh3r2NF12T0UIFy7ipZeMJiap2kq2Y4eUnlKkYxzfajFdBIFau8dzpTnbdCv3G7LzXxjEP5gYqByHziZXIN1oPaLMxO1yOHyeKbGxRmv0r9BH8o1XOx7MFIHULLFEZ55pZpyeNXh5wD1MPPYpOSnTKL5QWXZnPXXe7wLprMHLvKaWNzlHAj3GdV6Ti0cGMF3H8JUOi5+mQw4xz9xjCvLZ011aTBfvOYUk6GUu0j3c7iXUK3hGAv2Hf3uzH8FEb1yerzlaIH3i/IeG7rNRTqcJThbJe5GkmTONVh3Mw/5mj2BpzfqA7V7M1VjuU3sqjwFYVOh+xgS+z6BELtBEhmtY/C8Bh7p3N8pMcJ433FDLgIRulJRIr7/uWxMhmPT9w583Zdjkb0OSiU8P0rPPRpDYr0u8kg7ej79diwKtWmUqx9FH+2bu//JL5Sw6dDBeHWuf+rDa7vXdd5vdf9zzpf7OOkwgHRr/qzf5dprpdwbqNN6Vg3LFUayLeVl/P/RZpbwrsHQxLwmkMxmvRArUjtX67R/jdOGFprzDhgUOMKawXbPxMdy6tJ6y3Fruk09KVx61UAkUet0wZ9FXqexQP2ZqJyl6l9NkUaET+VhXprwhcGkQU+UClRJjGhxK9CyXy+VunBIo1I0xT+iUzjPUK3ahBNpOqiwqfARLmZbQWRvJ0F3cpQw2CqQj+NZovZTrJ4Z65wvEUqKPOFHbXnhXFS2NGryDVDkoV4eW+XI6/RaMDxd+OT1duuIKlWZ30X+4U05KFessD0v0Aa+V/Er7WrBVw8KYg1qyWXNwO8R7Blpzc70tSxlOvcWZ6sfMwAbDMjPHg/MbN65us3F37TJmUf+xoN2R9D2wyd+GJGnNGvPGX3ghwhPcWuFmWnkrgWf2rmQGkPv3NxUxO7tyxfDYRw+O/12lBPnwgVfT27zZTKg65RRznie89LXXGjdQkC7jOe95S+isK3laCVaRwMSR+ZmD5XJriFfzpEAajLEpD2Wy1tNaPzlMo5KZaa4TGKLeEP0Aput/3KTV7Q7SwW5nkDPOkH5rZjxxXuJirSXLTcIV+p2B+oHDFEexhjJZG2mlWEpkUa6/Mcs6FRMn8Gnz5/OaZrGvQHotbrRGO15SJhvkAl3OswIpmZ2Kp1CJFCibFYqnyL3fuKF+ynECl9LZrHiKFOt2KX2HU3Wt9YScjgq99Za5z1275J1Fm57u94KqMK/MoY/68WeVRH/eedJIJrgbK1el4zHuwWv/xsxfRvClSnFW+h6Uk6NCEvQsl3ujoWazQs2sHd57CM7r1VfNxKqcHDMzvKbYtMlM7mrRYs8gfQ9s8rchyQx4gfTyy5Gf45m966kMruwc88etmW1sP0Dtkk2c+kt4McB04FlsHRQ6YqW7wt/II3JQrvnNB0mgIUwRuHRHs8c1rO1Cb9IfOdR3XmysNj37vu7ibqWzWSANYqpOcoc+yGG5QLqCZ1RCrIqI1z4sUEqKmbzlCdYG0im8I5Bu414dgHEdtahwe6G4vETeg/kazBQNYLo3HMMD3KJUdqg3fymPNF3JUwLpAl7xXsBD/vdym+7iroDbn84A3ca9iqHUHeRN6sssgcs78GuIcoKmMUhp5GkUX7jv0xDuyXygRArUnxlqxSaBMY+ta9FLm599L2DS0S23+L3cEC6c68nUKbwni/KwpH3uwUs1LH6a97jHxOUvzdmmFmwJeX4MpXqRiwN3unuC27ZJ9zNWmWwQSAfyq/7FQ+rIspB5ff65WabSE4wuNbWamcBBWLbMjNckJgbmu7uTvgc2+duQZD50kF57LbL0ZWVGe3c4pBH7rhUowP7skWV0VCIFApc+51ijUqen61NOEEgDnUaDfJfTKp27mnaKp0gX8KqE0erBzOa9kYc1zPGT+rRc4z2lkIRAb5+cHBWQqKe5UmlsDcjeP8bN7W5f+WE9NgSkSWOrVtNWTsp0E2YFm0V01X+aP6J4p2dQ0qXmbNOp7kbCQbme5XLDWexSB1ZqNe1UQIJiKFE8hd4QCwKN42aBdD8m0tvnHOu9/secqEfcHkVgxh0S3W6Uzdimf/MfdWWRurJIN/I/N7HmuUm0RB1ZqgP5xdsQeDxxnme0vuUI93vx3e+UZiN89v30dLkwPvsPMMa9qpjLS9ChyNZfWrFJ3fm72nT+0o5VWkqOfuMAXc+jepbLpfR0rW3RWzfzkFItc+/DmagvGaFLeUHBvYpmzUyojXnzTARaz/7Onf3cOKvB7NnS2WdXHrfYU0jfA5v8bUgyMdLBdI+rg39s/+eek+ZlHSkIChXsJ5MZKosKt+eJCSS2liyB9DA3ahDTlMJOX0gGt1zCC4qhRCsw6und3CmLCmWwQaN53mu68chFFwUV9IorJMvSg26C9ZfWrNd9jNWPHKoYSnU+r2k4XwakuR4z5fMU3ldLthjSTkrSzpfekYNyncvrsvwGnkHKYq2e5TIvSXru6UzeEigg7ML7nOI97wHGePd7bNgWFd5ZvgkBRO3Srdwn4Ruw9YjHrj6cL/207go9we29QuYAACAASURBVNVqwVYNYppG86ybNE20UE/D+DA3qpg4fc3RusbxtNes4ilLAgWV7OuBYhrCMxlfI9IHl47lU29j5tl/UseZusT5iuIoloNynclb+jPmAL3pPK9Sw7Vvdp5mzzZjV6NHB47ZHHZY9ctuulzSjz+GHivY00jfA5v8bUgysVUgspnyHpfFO0+eraMSJntJIpYSraZdyBr+gDuWe3tWeVerasM6ncfrWk07tbI2qyfztItkCbSQbrLc5NWX2bqN/6otq3U436kri3QK73uz96xPC24PIj8Pnye42ntsEFO19rxb9UPCSI0IIvqpHBQQbgFkJl+BvuMIgfR//FP5JOl/SXcIpIH8rngKRRgTiEWFvuNwrzdSCjtVjmGlpXQKmAU7jlu8J+7DAh3KjwF59WOG9uNPtWKT+jNDh/KjCkjUZTwXkM4Qvn95XBrG9/on/6cYStWatTLmqgod4r7Gm5ytTDYoizXeCVoJFOqwmJ+95qVOLK1S44+hVEOZXEPSN9KZJQHb8RR5G644inU5z2oxnfU1R1WaQDYq8XsteeQT5eebVa+SkwPzvvzywEBsq1aZ8aI2bcz6EhUVJnbSoK6b9hrS98AmfxuSzKQYMPHqq8LTT5t0lx6+SK7EJD3sXoDEX7qwWJfwonI5OyBYmSFBlw7hJ5Xh1LF8rt78ZQg28yyvdufCaMqegcxuLPS6djZza8L+Ihl7tWf7VOeH+pFDA4j/Yl5UMXEBI4IX+k24CjYftGW1XJgwC+9wmtLIUzK7AlxMu3i11MoDmqFs3ZfzjFwYO/9Afveu2wvSYXyvq3hKP7l7ST7N3Bz3mHMGMTVAOw4nTr/JVqfwnvd/EvmyKNfZ/J8hONYG2OdH85w+4Xjdy1jFUeSOrln5/upfXBrKZK2knT7gH5WOn3eeia9fXm7chj0zgQcMMOM2TqeJDuvBwoWmZ+iJoDFihPmWe/SofO0s1urJ2BtV9Opb9VfhmgBs8rchSfrLcLDP1S8E3n/fmIRPOMGEKfDUFv8G4Doe0wl84jVXeMj7Ul7QM34Tfs7nNd3J3XJQrnzMmpD3pz0okHdw8xoeF0iPcr3O51XFUaSjqRxm93lGB7icBstjXFtp53JylES+juVzHcNE9+5ADd4zMAw+e/nFvKgB/KFezNXDXB/yevsxQ0fzlUDqw+yAY935WwcxTWBs+tEi1g6s9P5PYUcIt0qXMtggqFALv/GP/flD/+EO3c49AulzRqq/O5poOHEEmbqiLT2t+frt7gl6PrmyYnEGbymvRWe5XCa0s2eOweDB0gMPmLY9LU369lvzzc6caVZe84xfN29uYui3C9FBzWKtnuRq73KgxdndNHmy8TjbE2GTvw1JpgsM0ocfhj4+aZIZqx0yxB1rP8gb5Dxe924WOpJVjkMz2ozSw3G36jg+qxToy5+wpjBEFdkdVfZ6ro53fiGLCqWyQ9tork4s1QnOz5VmbdNZ5KqV25c9lHh6CsHSgi06kY+8M11doGOYqGR26gQ+FkhxIc5NI0/n8oamcZA2kKEECjXaPaO5Gwu9xH2Z2wXTX/y9cTzyApeqD3PqTI5OSgUVOo133WRcHnDvI/gyrIkmjmKlkadECvQbAyXQNAYFBJqrLA2n+T+SeJv+e+qsSvv353etwaj3fzY/TANN0dWli1FKXnzRzCru3t2s3TtligknXunZhZh85k/6K+mg5xmtE/nY6zp7770NWRMbDjb525DkWww9VOje2bONF0XPnn6TZIL8wD2TlcAspZf/8tu+NJalchz6g/29MWv8JTNoxidIiRRofbv9df4hS7yx4A8icAZnM7arPzM0j556gDFuN1Df8S4s1kW8FBBvJhy59eSvgH0vcZHXW6Ujy/QE1+g03lWc243TQ7ogXccjlUgy2OxzON8FaOeRyIH8qsV0DNjniefjX3ZPrKKqpUL/4kFdzRMC6S3O0FccXemZBr+DA6s4Hk0Zyk8h9zdju97nHxJoBR10BN95n3NysrR6tbHhg1nX4YMPpEMPDX0NyzK++p61GLKyTMylbzLP0S2Mq9Qw94/7S6++asKd74mwyd+GJOn3380b/+yzwP0rVkht25puckDwqxAzQI90mIFNh1WhQxw/aydBAd3dspUWSsc3wGaFsI97pHPnyvuO4Fu1YpNi3BOmnuVybaO5BrnNKTURB+Waipms4D/gK8xs4E85Xgfzc8hzPTNnI5FQPYvq5Dg+DXg2CRTqB4Ypx4qE7P2lQtfxqM5yh7QwvbDw2nxbVutDTtIrXFgvRB8sg4Mabc/s6dN5W5tJ10ZaaRRfeMcmYinRTaPmaXm7IV4z4HH7rVb//qHzdzpND6G1e8XKzEzjynnyyZWXZ4yhVGcxXlPjDzdLg+7BsMnfhiTp11/NG58wwbdvyxbTjW6eVKK/so6uHOMlKPbL3f+YLcuSXmh5q5yUaRDTKi867hZj7/bt+i+3RUwWLdmsZHbpIKYFjC3URtLZqHHcohV+Ywb78WdAopn0i2iQtaaSzQoNd6+aFSihiTnY0yUyCZVX6Pw9tvwJ7uB1dZfwDUy4SWJOypTu2Kr3OFWbaakT+djbi3JQroudr2nj+TdrYcK+6sYCOSlTG9aGvc7AgYb4wSy806FD6HRtmhfq7uaPah1ZYeMY7Wmwyd+GJGmqWfvDG52yoEAaNEiKjy3XT/FHB9aUMKFtv//eHP6SkfqIkxRLiQYw3RtLPljO5C1vxfYngxJiVRqTqFH91oSt1FVJcICwFHaqN3+FjC0TSoYwRW/HnafbuUc9matgz5tgiaHEO6sXpIOrcHn02OIv5QUtDTLp1I+4dCTfVJvuUCbpVu+aBdGXjFRfzyd4RS5/OTZ7jv5kP53Ax95ej0WFTuYD40acm6vPMy5QIgXebydUQLhhw3xE7xmecjgqh2gYMsR4uJWUNGx9awqwyd+GJBOPHIyXRFmZmR3pcEgfZYwOXUtDLGqRn28q9thEMznqC0YpniLtyyxtJKNSHptJD+m6uYlWKiVGx8ZW9uypjTgpU8ugcAKJ5OtEPlIXFldJnGBmnh4bZOLxNFYx3vEEl1qzTlVru+Vqwzo9wC26nGeUGGFjVJ/Sks06q8aTsiKX4XwZNpSD51k5KfOOy4xyTJTP68qlw/hei91LeG5v39u9vKc5L9iTCkwYcX9f/9RUs0zk6adL+5mFzpSQYNw+Z8xo+HrWlGCTvw1JxpsHjPbuP3s33NKE3pWTgkL+HnigNDRmmjfdNxylRArUk3lebxthQjWU49BLXFQp6zHcH7GW7iGP+iKvZuR5Y/J4xH9sIHimadUS2tTRcBLYMAVProqmJLNTg4Js+R656CLplVd85fHETPKX/ayZmsm+EmgTrTTW+aA3emgLq7LCEOM3qB8bazx9Pv3UeOp4egA5OdKDD1Y/23dvgU3+NiRJ331n3vi555rfO+5wHwgX3TF4UVWQkpJ006h5iqPY6yst0DucpiR2qSuLtIr2+pvupoLzp352ryMLxuWuNkTjsYUn18AmnsMyXcMTupO7vbH961NiKNUh7klu9X2txpbq5gEclzM7RM/JSGcWmyB9ubla3e4gXcfjASa1UK6aHlNaWlKx7r/fmDDPP9+3PsORR5olNMvLG7GCNUHY5G9DkvTNN77KdIn1klyemha8YkUVMp8euqv5owLfcnuTGapYStSZJUphp3JYpuvdrpHBvuihZsWCqo0VE+68SGQQ09SD+ZX23+eIfADalqrF//20iQtnApJG8oUEWtR2mC65xGjwFhXu7yR8o5nlWK/HzvlDr75qxqnAmH6uvDLyYG57I2zyb+qobjWlCFZbigSeeD0HM1llVLEMk5+8xvn6imNUgpkz74mO6ZGbGRfWq6NqqZl2fC6vKYON3kk5/o1K7yhMqqoviQ2KJbQniscslsKOkI20Rbm6YkJzt2SLTnV8EHHeGRkmzMPYsT43zm7dzJoP27fXoC5FqQ7tbrDJvymjukWka7DIdKV8/T72H2//xuuB8ROHRFTzSoj1xodvxnadxXjlcnbA+rLVSTcWRpw2nLRnpfbjT1lU6FzeEEhn82a9ElpVs4wjleAgcnuSxFBSbdjnSMJCVyVHHmksj57V4o47zniqVVTUsC5dcUXt6tAeAJv8mzLC2dv9VjWq8ngoBFWCOfRRc7apfUszwDqdARHXQE98/erEFzunfsV4jOz5NvWmKDXp4dVkbKbyOy4O8Ny64AJpyZI61KVwiw1XVYeqqlu7UQ/CJv+mjKo8bSI5Hgp+lWAF2WrLGrVljV5oOUYgzaRfxDVxBdmNTjrVSQeWywU6iQ8bvSy21E38ewsWFfoo49LICTZcXfGTLbQ0QQah6joUCrXthTciqiJ/BzYaF9nZVe+v7ngorFoFwFZaMoKvKCCZrxhBy7wlADhwVVusLaTzM0P5kpE0Y3u16f3hpIx9WFCjc+qC63mCbziGT/gHVgT3ZqMpQeRYKwEBwkmF98jD/IuTN78Eo0fD+PHVZxWiTqylLe9YZ3Elz9CHv2jFVk7j/bDpq8Ttt0NhYeC+wkKzf3dEuFahKckerfnXh83fvbThYKYqniKvjf9d6wyBNJcg756UFCk9Xa9xvoYxyb04eWjl6Qz3alUQPsKmLbZEIpmO4MVVfGalU3lPzzFap/C+hjNR5dmdqjW5uN7M1dKEXnqN83Uhr4Sc3HcSH5mV12qjsdemF97IoL7NPsCrwCZgrt++lsC3wGL3bwv3fgt4ElgCzAEGVJf/bkP+tbUHRtnbp+yN8TrOMUEWFfqQk81rTkrSW5wpkP6me6WPt+jVt6qsqPUht3JfoxOQLdGUcu3DfEU60S144p5nERZ/pcJBuS7nWeOWHKQEuRKTNO/Bz/Tcc9JZZwXG7w/2OjrlgJWamTWybrb62oy/NTIagvwPBQYEkf9DwK3u/7cCD7r/jwImuhuBQcBv1eW/W5B/E7EHulzSxRebyz/b8vaAj/3N9OsE0iK6SqA80jSD/vqg1WV66CGpt6OyL7wttjSGxFCqC3nF+60KzPoR9NdjXKeT+dDriQYmdPOZZ0p33y0de6ypepZlQj7MmROlytVE6nhNUO/kb65BxyDyXwhkuf9nAQvd/18AzgqVLpzsFuQfba2glr2IO+4wl73jDhOHZ+5c6fPPzTql6SlGo0plR8CMSo+kkReRa2Zrd2z+urry2WKLkUDvrRR2aiRf6D7Gahy36A7+o5FMCFgsqDNLdAGv6lUu1JIlZlH3m24yXOxwmHDO9TL5y/b2iYj8t/v9tzzbwBfAUL9j3wMDQ+Q3GpgOTM/Ozq7nRxQFRNMeGKRhVGDp6djr9dUt3wcsNF1aalzgvv3WrHI0fLg5JSPDxDMPV9naOAJt+sMd3+h5LtUmWuknDgloGEIFZfNVwKoCptliS/RlCFP0GcepAlPf1rY7QNddZwK5ORwmdMmCBdGr1rs7qiJ/yxyvOyzL6gh8IamPe3u7pDS/49sktbAs6wtgnKQp7v3fA2MkTQ+X98CBAzV9etjDTQMdO8LKlZX35+TAihW1ysuFxTraMpt9OZ33KCQFpxOaNzdVYccOcIVwbmnVCjIzAyUjA956CxYuhIQEKC6uuggOKnDhrFm5bdhoJOyzD1xyCRxwAHToAO3bQ/wH440nzqpVxrPnvvvgnHMau6gNCsuyZkgaGOpYTD1ed6NlWVmS1luWlYUZEAZYC3TwS9fevW/3xn33GZc0f1ewpCSzPwIsXAiffALLl8PylS+wnE6sJIdS4gPSVVRAXl7VeW3ZYmT+/NDHi4vBSTkVVbx+m/ht7E5YtAhuuSVwXyZH04HudGA1HVaupsOF8zl27ef0uuX4xilkE0N9kv9nwPnAOPfvp377r7Ys6x3gIGCHpPX1WI6GgUejqKWmcc89RjM3GE4ihTRjJ8kU+Ekhyft1o6JNO9bO28bSNfEUKikgn/6xf3HgIQkcfEE3tn/7O0Vvf8rg8p/owjL+j/MYyzg2tOhJ+rbFpLOVnTSvVJY4islgM2sD2mgbNiLHf/k37VjNRbwR4qjoymJWkkMXljGFg1lHO0YykV2kMp6z2Ze/2EYLtsVnsTymG+8WHMvXjAjIJce5hvgu7dm5E/LzoajIKEcA+8bOx1FWwhZasZhu5jsvg2l3f83Ht4Qo0t6IcPagmgjwNrAeKAPWABcD6Rh7/mLgO6ClO60FPAMsBf4ihL0/WHaLAd86oqxM2vDMB9rVoaexZ4YbQ/CLVbKUThHbStuyRgPdMdV/ZogqsHQpzwek8YTpdVCu1qxTIvn6gpG2S6Yt1YhZBc0/xEdCmDUQktmp1bRVDsvVjtVaRxv9wGFqxna1Zr2e4ko9EjdGl/KCDg2z4PurXGD+pKcHDLi6XGZ1ui1bVKn+lOHUZtJVSmzjVfJGAHZ4h90AodzIwonTqS20VA/mqznbNIc+2kJLPcVVGsD0iLIIFaflFN7T5TwjO3aOLfUhQ/lJi+isfsxULMW6kFd0AL8KKiKKGzTA8afm0CdwZzhXy93QJ78+YJN/tBCBm9f06dKJJ0q//FLDvEN8rBVYKiVGpcSoDKfKcagCS/kkeWfv/sihlc6bTV9dz2Nq5QgfV90WW6IlllW93pLBRq+LsPc8z2IvVnmV53djoaYyuGYB2nZDn/z6gE3+0UBVH5Nfo3B60ueVvs3zz5eWL68m/6BuqgvUjtWRV0Aq5KBcTsrkpMz2wbelSUkyu+Ss4TfZmvWayHAzu7cqCedOHUWffJfLzJtZtUqaNUvaurXWWTUoqiL/qLl61ieahKtnOFdOyzKfoBsuLN6JO59bU59m9dbkkFndeSfcdBM0axY+fwGvcwHfcRRz2JcF9KCc2Ep5NWMHffmLvvxFOlsRFuuttszMPpH561tSWmrSxVFSyXPIho2GhzDDfuHR3NrJ8xrN6byHA1/dksPJClcHZtKf5uzgSH4wByJxpx5v3D61chX5HXqSd9N95B16Enl5eGXrVsibOp+8n+aSVxBHXnwWeRnd2VqeRl4e3roEMGwY/PhjrR5Ag6IqV0+b/COFwxFA8v74g4Hcy79JopDm7KAZO2meWEaz8jziy3YymWGM558hz23dGsaNg3Ost4i98tJAV9G4OCgvB5eLEuI4g3f5lJMAOLrPembPj2GTK8ObPJUd7ArhvVMXWFQg2+3TRh2QyQY20ZrqSD8uDp58Ei5KeAuuuIK/i3KYSX9msR8zHfszK2YgO0qNd9sAZjCJw8lLaMfW2x8l76CRAUTuJfM8yFu4ibzFW8lTC/JoSRlxNSp/y5QSuvaKp2tX6NIFunaFww838wmaOmzyjwbCaf7AFA7mSp5lCV0pIilkmkjRwtrOQP1G95R1JJXvxFFcgAsHEziWefSlFZs5Kmkauw4/kW3bYNq0ml/jGh6nBdv5kcOYzGF1Kq8NG9HA2Ywnk40sSBjAgtSBrNmaRLnLF3E+Ka6cxNQYHKVFlOWXsFMpuKrwVE92d7oLCiK7fuvW0HX7H3QtmUdXlnilC0tpkdO85hM1mwhs8o8Gxo+vPIkrCAI20IZldGYpXbzi2TbaT/0ijhJasx6w2BiXE9BVtWGj6aFqM1BiIqSnmxnq6enQsqVPWrQwHeO8PNi2LVDrX73a7PNHB1Z5Cd2Q+1K6zvqAzp0hNZXwvXvLCj2VfjdAY83w3bMQPInL4fDNKHHDArLYQBYbODh9oel3+mEXKSzPOpilz3zF0vf/ZOm701nmymEpXVhJTkibfiQ4jB8oIZ4VdGInzVhLBzND1yZ+G00cTioCZpq/xZnsxyzS2yfTYtkMnE5YuxaWLIGlS83vkiXwyy/m11+zdzqN+b9rVxg6FJ+Z5vKj6LR+KokExTTJyYF+ftvZ2aF79zVd9GV3QbiR4KYkTcLbJxi5ueEnYnkmn1Tlahbk2lmGU8voqG85Us+3HKtLL/VF4axOYilRFqsrxTAHKSZGSrbyBRVRWZTcFlvqS27kYT3DFbqBR3QCn6hXLyk+PjBNXJzUo4cJ23zdddJT5/2uiZnnaTFdVZrdJbRHT6Run3ugeyi2t0894cor4fnnQaICB9MYws74DIouu57iAw6l+MdfKfpoIsXbiihu3pqiQ4dT3LUPxcVQ/NxrFJFAsVuKSKSYBApJopAk8lt3ZdMmQC4sZMfasbFHYARf8hWjqkyTSCFdY1fSelhPysth3Tqj5btc8M47cMYZ7oShTLFJSZQ++zIrh5zFsmVGkR82DLpPjzDI2/g9KxicbfOvT7g/lk9X9uMkb/giGzZsRILD+IEh/EJXltCBVWwik1+ch/Bl+rks25TqTde3L/z733DqqcYEv2EDLOt/Css3JrKMziynk/d3De3xX578rrvg7rvr8SaacINhk3+UkJcHp58OGzcaZaOoCNbv/iHpbNhocDgp41Am04HV/MRhrKRjyHSdOxvNPSnJONwsW2Yi34YKSd6BVXRnId1ZRPcnr6J7d+jRw7hkWlV7mdYeYXofvPhik2gAbPKPEnbuNPHCFy0yngcnnACvvVb3fJuznWxW0T52I/ObD2bllhT++U8To7ykBEpmzqf4598p2VVGSXJLivsMpKRNDsXF8P33xuPBho29AcnJ0L27W758jO47fqMHC+jGYpJxE3Bt1tCoLaK5jkc9wPb2iRKaNYPffjMN+pdfGoefoiLjUrZ4sbFLLl5sZMYM801E0rbuII2/SOOvMmCL2Zeb65+il1uAAmizEtpXGFe3Pn1g1qzo3qcNG40JyzLc6SH5Hj18/9u29dPix2fC6M9rvYZGVLBqVc32NyWEGwluStIkvH384oSUZ3fS7Sf+JZAGDZLWrg19SmGhdNddxmMhNVV67DETulmSysvNeT/+KL38sjRkiHEuyMyUEhMb3/PCFlsaQ05KnKibb5Yuush49Fx2WdXV0vVmrsqyOzfemrpNPHoodmC38HjmGenRR6UPPzQROTdvNkGcAhDGBez9a39ScrLUpnmhprU5OewHuHixNGKEOW3ffaUpUxTQmMxve4TANBBffCFVVIQv7+uvS926BRald+wCtWVNo1dcW2yJpjgpU1bzAh10kNSvn3Hx7NhRatNGatHCKEkOh0n76KNRJoZI0cTdQ6si/73a5l9WZuzqwaa5pCTT7fTKuw+Rs30WOawkh5VksR4nLsjJYe7lT3Pibb1YrfY8y5VcwishB3wk+PhjuP56M/vwQuf/8WDFTWSwhQocPBj7b55OHsP67Um0agWdOsGAAWbaeVpaoHzyiYmBAhBPESUkRv3Z2LDR2Egmn2QKSclMJKVNKikpVJLkZPN79tlmUlejwPb2qT/U54BveTnMnAk//ACTJsHPP1cZwQGAWEppzxrTGCRvJbNgKV9yLPPoQ1cWcxrv0TINEu+9ncREAgTgrVM+4K2CE0mmgDGM42Q+JoUCnO2y+GjsH9x6q1mWLnoQqVY+u5RafVIbNuoRSeRTgTOkwhJHCV1YQg8WcCiTuR63hhM0eFpa6gvatnVroCQlwVVXmfE4D9asMfV6yhTo3dtMzwmHLVuME8euXWZp1d0dNvnXAKWl8McfpiGYNAmmTjUeNx40YwddWEoHVrMlvh0rS9qwjrYBfsU2bNgIjzhKaM8a+jOTnswn05FHxhWnkvLMg2wjjTxaspX0AMkbcLSX4KtSjLJYy2dtLuPPUXfwc+lBTJniazdiYuDmm+H++wPPkUy4iOeeg/ffN/X9hBNMD7veXEQbCFWRf0hbUFOTerP5R7DYQ1GRNOm2b3RHzP3qxFJvCAUH5erYapdGJnyvmxmnx7nGz1ZZqngKlW2tqPECFrbYsqdKM7arO39rHxYonc0hw5FEKklWgQZ22qJ//lO66qgFusj5mo7mK7ViU6W0w4ZJzz/vXtvXDzt3Ss8+a8bhPGkPPVT6/vsQ4367KbBt/iFQw8kZyh3PgIv2Y1ZZ71pdzkk58XEQlxSDs7wE8vOpwEEZsRSQUtu7qBIp7CSJQizEdtLssQEbuz1S2U4iRQgHxSRSYKXgUuVedwab6B2/lH6XD6ZNG0hI8MnGjaZXP3mycdUGM3/n6qvNhLKEBIiNDRTnbhpdxTb7hEItJmcUF8MDD8BDDxk94brrTDvxW79LeJuzmMSR3rSxFBNLOYWk0Ic5jGQiZamtKDjzYgoKoHDhagrmLefb4kOje182bNhoFEyYAKOqDlvU4LAneYVCLSZnvPSSGQRKdY+bPvSQsRMOTzwZioxx8A7uoQXbWEAPpjKEefRlLvvyN704fNcPjOhuVgHq168DW7Z0ICvLNCQ2bOyNcFJOJ5YzcFAMXf/+nLgdm9hCK1bSkXn0ZgndAONk0ZP5lBLPBtqwnRYApLOFYYl/MKToW9qzhmJ3gMRiEihOy2Ltubfy228wZ05gSIiMDONRl5Bg9nukqChwu6ws8ntJT4/mk6l/2Jp/MMJp/uPHs27ME7y6djjLk/uwPGcY87e2YePG8JdIZwsxlLORNiGPD+y0lYM2f87X+Qezig6UkoCFq9LgsYWL5uzwfvDgoitLcOFkDe3ttXlt7DY4gY+Jo5wMNrOIbkzjYIpIIjUVWuxaySpyAONYMYRpDGUKTipYzD58znFsJpM0tnEqH3AWbzMsewXO+/8bYMItx8kXcafwfPfH+PqvtgHXH9lvLXc+345Bgxr81hsFttknFGpi868ibcFJ53DPPfDQQwIshvIzbWK3sro8i+XqGJXVu8Kto5tIIcOtb/jcOoEKl+1tZGP3gcNy4XA6vHGpmjWD/Up+pXfJDNqzhkSKmMwwpnAwW8gkjhL2ZTYDmcE+LMQCymOTKD/5NMr79qf8zzls+246f+7qxiyrP/kKHEc7kF95mms4IGl+kwm61hBokt4+wAhgIbAEuLWqtI3p7SMpoincnTtL7dqZ3R07Sp/c8KNcDqfySdLXHKXWrG90bwtbbNlb5V5u8200kdALM59E9AAAIABJREFUDQGaWngHwAksBToDccBsoFe49I0e2yfcil2WJcnE8HE4pDvukCZNknr3NodH8KUW0dWbPp8kzaC/OrDSm0UfZiuLtQJXo1cQW2xpSuKgVH2YrTMZrwe4RRM5Ritpr0200lI66b77pK5dw5/fmSV6gDFaSYfAA+56uzegKZL/YOBrv+2xwNhw6Rud/KvR/GfMMJvvvScpN1el2V30GNerGdsVR7HGcp/ySQo47zXOVzxF6sgyHcvnAukscvUZx+oJrtE1PKGRTFA7Vjd6JbTFlvoWK4zPfwylQXNlXEpml5yUCaTWrQND6yQkSOeeK82cKbmyq663ewOaIvmfCrzst30u8HRQmtHAdGB6dnZ2/T2dSFBN8KbXXze7/n7os4B062mt83hdILVnld7jVLkS3eelp2sShyoes07v6bwtV4gP9XGu9VaCxq6gttjSVMQK6inHxUmHHWYi5M6Z446e28SDrjUEdkvy95dGt/lXk/amm0zY5rLsziG/1CmOQ7QffwqkI3qt17x50sZn3tdA6w9ZlKsbCwXSLYxTOSZMYT5JmksvvcnZ6sTSRq9stthS39KCrdqfP3R60ue69Vbp4ourP6dbN+nss83M3JQU3/7ERGlwt026OuFFTWCk2ZmevlcRvyRVRf6N4u1jWdZg4G5Jw93bYwEkPRAqfYN7+0CNovQNH26Wc+zy18cUk0Aqu0ghn1R2ef8nn3sKf3AAH31k/IcTEqC4qAKXy7LjAtmwQQX7sIRejgU4BvTn74Js/v7bzKxt3dqs2etyVT7rmmvM0qpDhpjtRYtg4kS4984S8vKNC3Qb1rOetk1qecWGQpPz9sFMLlsGdMI34Ns7XPp60fzD2fHT00N3Fa+4Iqzmn5UlnXGGdHziN+rCYq8pxxZbbPGXQFONx27/r9TndDVPaJ+YpXJYFZXO88TstyzpqKOkCRNM9TvpJNPjBlMHR4yQBg/2pe/PDD3GddpApi+zvcjeL0k0Nc0fwLKsUcDjGM+fVyWFXXutXjR/h8N8DpHCskAin2Q20pqN8TlsvPwu5rUaxh13mCQnD1zF+hnr2KBMNtKaIpKjW2YbNnZDDGAGC+lOASm0II+T+Zgs1nEfd3DtMX+zePJ6JhYfBkB8rCgpc5KcDM2b+zT+pKTATnqzZtCrl4nyuXhx4PVSUuDE/FzG8gC9mR940LJCdyH2UNiTvEIh3AxfN77jSD7gVEP0tGYDbVhPFsVVBEdztw82bNgIQj9mciOPchbvsIHW9Ldms8NqQbnLAQiwiKGMvtY8lib0ZGeRb9b6aaeZRYw2bTILIa1YYWL5R4J2rCGbVYxkIndwb5NZWL2hYJN/KISz+Scmwtat3MCjPM4NVWbhH4ohM9NoKsnJEDN/NqtK25BIEWlsYxepLMO3zJCDClwhZuzasGGj/nC8cwJ9j82hz5l96NPHLAgfF9fYpapf2OQfDqGWXwNvo1BGDJvJYCNt2EimtxfglYQcvis+BDBWpOp6k7GUUOaOwxNDKQP4k7aso4BkFtGNlXQEe/DXxl6MBIroyHIyDulFUpJZTCl48ZYuXWD//WHbNpg3D9at8x2Lj61g/4rfOcD1G63ZSAr5bCeNuXH7MzfjMBZuSKOiwqSNiTENQJ8+0Lev+e3TxwR8c+wh1dAm/5oiuFEYNQreeCOkZ9Dgp88hIQG++87YHzduNLLmvWlc+NKQEJmbLm5oyC17yJdnw0YESKCI0bzILTxEW9YxrfU/+L8TP+S992D7dpOmdWvo1s1Uwdmz8RJ4ly4waJCRgw6Cfqd2I27VksoXcZt7Skpg4UKYO9cnf/0VaAlKSjLLPXoagz59YN99oU3o+IxNGjb5RwMhegk7jz+HNm3giCPg6KNh2TJYvhyWLDEuZ54PNBCe5x3YACRQVOV4gg0bTRtGqYmllEQK2Umae7+LBIopJh5CmDqTyWcCo2jHOnL5J09xDXmEjo2cmgoHHhhI9hkZQYnCOXIEDfQWF8PmzWYcYdMmWLoUfvzRLPISajzBsswawENC6XNNGDb51xJlZWaAaflyH7EvXw4LFsCsWaHPiY01H0ppKSTFlVNYapZMcFDBPiyiNRvII511tGErGYTvBdiwsefCSTkV1Swn0qePj+gHDYIePcKvqFVebnrem/oPZ9P6cjaRySYy2UyG+Z/YkU37HeMl+127QucTH296GZmZRjIyzG/79nDRRcaTaHeCvZhLFSgrgxkzAsnd83/16nDae9X5eeAhfgAXThbQkwX0jFLJbdho2riGJ4mljC84jkV0B8zi7dnOtSyp6FzluQ88AJdd5tPMFyyAn3/2bfvL5s2G+I0e+3VAPk7KyWALGa3iyUwyPQcPsQcTfGamIffdfdH2SLHXa/5jxpgVuWzYsFF3xFFCdxbSmWXMpD+ryKnWu20EX9KMncxsdjiLd1a//kWLFpUJPIDEZ39L5mvjyFw3mxbZqTjuv3evmtXrj73a7FNYaAaNysuNVh78u3kz/P574Oh+cMvveUQek6HLHYHtww+Np8GwYTDhszJcOO1QDTb2Qrj4//bOOzyqKv3jnzMphIRq6C0JFgQsLKKi4toQkVV0rbjoWkDsnXVVftaVXcvqrmuFxa1BVl1XV7Fg76wCigiCIhI6AqGFEkIm398fd+ZmZjI1mclMyPk8z/tkbjv3vTf3vufc97znPckJUhBZHpHbwkOLFk7UdatWjq+/bVvH6BcWOssFBc62goJaadXK2X7ooc2n9R6LZu32KSlxPg1TycsvA+Sk9iQWS8aSuOEv9JRzV80dZOOlmmy20YrtFLC9oCvbRo1l+3bYvt0J89y+3WmkzZpVN+wzHG+84eTbskRnzzb+U6fyF73N97Slql0ndp84gqp+A6iqclr99fpbvoWq9VtYWt0r3VdnsTQpzjx0OVklvcjOhoOfeYCrecLdJqCcQpZW9KbsxLGUlTnhl0uXOl/XZWXO5OqBFBY6jbvi4lrZd18YOjTJiocbD7QHuJH2XLdPInP01qPM2QzkUOZwODMp2SebTS27s2Z+OWXqxVba1q98i6WJEDi6Pdy2uQzgAOYzmP+xtrA/364oYOdOx5iXlUHZpfdStqktSymhjGLKKGY7waE0e+0VbNiLi2uNfVGR4/5JOamwI41I8/T5R8rd05DcHgFlCpjHQXRhDcfxPgvpV78yLZY9lFx2UUULumb9yLb8znXCK9uymRKW+kx/GSU5qyi++hSKLzqWoiLHz99gGtpqT4UdaUSap89/+fLE1oewezds+vO/2TjxSTat3smmTvuxcd0QNnEqy+jFQvoynwNYS1eqaGiCENHGVLBVbRpYjsWSOVT5Upms8XaGCujTdQv3lY+juOpbiimjHVtqsyEWFfkM87HJUyC01b5smbMM8VcADbQjmcyea/x79QpbYy/ocgIfPOHkBfHLxo11f2/fDs6EY2c5Bzaw07gVFfRiOQVsRxi8uS3x7n8AW9dUsHZ9tjX8liZHuBDOo/mQS5nEgcxnK224g9/wAceSmwuXVj7K6VXPBRfiN/z+VnQy/esTJgS7a8BZnjAh/jIj2BF67QF9fpES/WeS1Gsylwjzdw49YHVCE1BkU6VcdiqXnfJQHTIhRY1yqFR7NqgXS9Una7H695cOyvlGA5mtQ/lMg/lUQ/hQx/CejudtDeMNncyrOoWXdUrem74y0z3JhhUr8YuHKr3CydqNRz/SUVM5TwcxN2ifR7lS/ZgvkEYcvFKLF8uZjSVcgcZEfWfjnnoxdKrVSBfgP18D7EhTmQ6STJvDN1Gp90xeYebd3bFDWrpUWr5cWr1a+vFHacMGafNmqaJC2rFDqqqSvL65dO/h/9SOjQKpJdt1Fs9pEmP1Ny7QpUzS3ix2n4lOrNWoUdKfGasllER8+GpASyjRs5ytI/hEhaxXHtvr7JqT48xW9Coj9BDXqzOJVVxWrCRL9mNhnXXtKde5TNPf+KXW0Fmjs6YJ5FYExfyg/5rTVPNPn6GMZJD9s2vF2h7rXQ810pEqm0Rn80pkru8Mo/ka/1AS+Sf6HsRz+JfO4jk9y9naRr6zvrAw6GEqo5f+wkU6v+AFde1au6mYH3QxU/Qw12kyY/RrfqehvKn2lLv75LBLhzBLp/LfoOdzjJmiBx+UhgxRwNdBTdhn2YqVVIh/msVacZ6/fnytC/ibhvG6OrI27LG3ca92kOcsFBbWvn/RWtGxvgyiEaniCC2zCbXak4E1/lLin2/R9g+3DVRT0EpL2x6sR7hGw3hDnVgrQ+CcpDXqyI8aygw9zHWazUCtoZN+xstBRfVmsXUHWckI8c+R+zPPazJ13J6OtGJrnXX5VOjnvKDJjNUyega/V5EaYA1p+UeqOPzHN8FWezKwxl+q34MV7UEtLZUKC7WQPrqNe3USr6uQ9RGfv2x2qRVbAyoD24q30rSkvdkoT52vgcgS+OXQs6c0Zow0bZrjct006Vlt67m/dpGrml5FkRtV8bbUG1Jx7MFEM/57bpx/KHHm+U6I4mLGLLudvzDGXZXHTvLZQUvf3/ycavKLO5K/ZD75NRW0oJLtFLCBDszi8DpF9mMB5/EM/Vsto+1xg/j7ax35p/c8hCfqwBqLJZlkGy9essK+MsnmQOYxL/8IZ+AU1C/ap4kPxkoV0eL8w9YImSZpa/nHwhhV+yIetpEvL2E+PQMjGbKy6mz/M2N0M/dpPA/oUD6z7h4raZG9Ar5ax4wJfswvu0zKza7WYGbWOa4bK/Rqx1/q9tO/Urd2dYMWYklLtquUXzgLDW2lN+GO2VSBbfnT8JZBuPjjCRPCxwAHEhrDfMEFznMfBi8evqEvZ/Afvme/+K7LYkkyhhoK2EFhIbTr0QqPB778sv5ltWQnbdhKR9bTnVUUs5SerKQj6xnAXA7F92435CvcEpbmOcI3FL+BT8YnpX+k4IUX1p3bN5D8/NpJ4QHvqNGsnvENZf/8iDKK3Jwmyyjie/ZhJT1izm5ksaQa4WEbrdhWDsvKEz++Tx+46rDP+eV7l9Bm5YL456rbEwZONSGaT8u/IUTL7+H/Ali+HG/7Dqyq6UrZ5naUFR7CsmMvpKztwW6GwuXLnXkEoiPAkMcOillKNbl8zz7Y6R6bM84zkam0aAG7dtVdv4Te9GZp+IP8aR38WP98SkhZy98YczZwF9AXOEzS7IBttwJjAC9wraQZvvXDgUdwZnOeIum+hujQKETI4zF7WUeeeGc0Zb1HU+Zxpn10jXs58ILzs00b6N4djj3W+dujB3Rf9Tndpj7Ir3ffzXKKqSQPEAOYSx67mMMhLKI/LbOqwJu5L76lMWis/3/dSqYVWziBdyijhG/oz0hepppsVtKdLzgEYdi1y+DxODn033gDXigcR+cN8ymmLPxp8vOdr+bXXtvj0iQ3KSJ1BsQjOEa/D/A+MChgfT/gK6AFUAIswTH2Wb7fvYFc3z79Yp0naYO86kuEzuJH829Wt6w1GsTnOq3lDF059FtNnCj9/e/S229LCxdKW7fWLW7zZumRR6Q+XTcLpNZsVt+sRWoZMMo3l11qnVeV9o5AK3u2HMfb+jvnawXdtIVWOp3/BG0vo1f4A4uKdNOIBcrOlubMkVatcp7tHTsUPea+sNB2xDYipDrOP4zxvxW4NWB5BnCET2ZE2i+SpN34h4s/zs118i8ErosRkzxvnhM54S+qQwepZcv0GwAre7bks03Pc4amcY7+wLW6hCkayGzlUhnxmGcYpa20Cr/RF8H23XfO4j33hDzo0fLqNLMRtukmHcb/MeD8gOWnqU2ROSVg/QXAYxHKHAfMBmb36tUr1fcoNqFhZCEpHlwJCVerqpKefVY6+mhnc1ZW7ajJQGnD5rQbCSt7llzFo+rGSo3hz8EbfM9oFTl6mVOilrEP3+ksntO93KZX+JlW0N0ZlOXjxBOlHj2k3bsD3hGIPeI23DtlK4WkE834x/T5G2PeBrqE2TRB0n9jHV9fJE0GJoPT4Zuq88TN6NHBPklPhMFWvv6B1aud/qvJk2HNGujc2dns9ToTTQ8ZAoccAllZ8NLvvrGTwVgaxPG8zbvUzl/YhTVM4jJyqWIdnWp39EWgVVbCgy3v5rc7ryef7dzOb7iBP5BLFavoztyOw5hbcjpfzalmrncA/+Zst4jCjZUMGAoDBkC3bvDWW/DqzR9w2qSAiDhFeWWXL09Orn1Lw4hUKyQi7Olun3CE+bStAX3Q+Wydc46Une2sHj5cmj7d8fNPny4tXuy0kmbNkvbvFrm1H2mwVy47lMuOtLcqm7JksysN501eOo+WYTLAhspFPO3m3DmM/zkrff726dOlvTs5287mWS2nR+2BOTl105gUFWkrrfVx5zP02IWfa+xYadCg4C/Yiwuejf8CiopsOoZGgjS4ffoT3OH7A05nb7bvdwm1Hb79Y5WfkcY/oB+gggI9yWU60HwtkNq1k2680TH0fn74QZo0STrrLGmvvYKf9yP4RP/iHC2jR53snrXiTaoBsdJ0JThZYKg4z0gHflQxP7jrBfohr69GDlwukPbP+lZvcUL4QoqKpCuuiOmS2b1bWrBAeuYZ6Vv2i095v8+/IRk8LXGTMuMP/BxYCewCfgxp1U/Aiez5Fjg5YP0I4DvftgnxnCdTjf+idofrWv7o+usHFJVryhRp+3apvFz697+dDt7evWuf7R49pIsvlqZ2uEZr6eRueJvj1ZVVaTcsVjJf/supep+f6lImqYCKoG3+ZGoH80VQJXEXdyiPHSqgQg+MmqNd5CR20lgdtbEmT4HgSsS2/BuFlLf8Uy2ZZPx375ZevP59DfW8I3Dy8f+CUr3X4iS9e9tbuu026dBDJY8zF4xat5ZGjpT+9Ccn9LOmxleQ74XYRY5+ze/cF9XvkujIj2HejebR8q87Y1riksVutWdDlHPEn50yvVK3lZ9FlSYzRjWgSnL1IqdpJC8pGyc0uIAKncs0vcrJQceN4hmtpFvkYIVYEisDbpg05xGPbeIzZDUVrPFPAuvWSb/9rdTLF/bcnRU6h3/pV9yv4bymfLY5L2aWdNRR0l13SR9/7ET7hKWoSIvZW4P43H329+cbgfRbblEluVpCiT5pcZz+w+mawD0ZYIhSIU29Qovmgoksw3nV/X/7ZR++TaiM03hRG6j1IW6mjZ7mYh3P23X0KuW85FxwNFdQaWnk48K5c2y0T8qxxr+e1NRIM2dK55/vhPX7n+N8tgXl7t+fb3QNj+hlTtWWLfGV+/fLPnE75PbhO13O4wLpSh5TTciLs4k26s/XMd/LG3kgaux2Zopj/J2skl7fhCHB2xKRbHZpb76rs/4hrtcPFGkJJRrMpwLn68BD5IF07VmvPLZF1cNDdQwfvCMTuUUgtfVNCTqED93pQf2ygu6qJFcHhsyH65d2bFQxS3QM7/nO6dWd3Bm003Za6nbuVgt2qgU71Y2VyqJKq+gaXcF4JNysWKF9A3GGQFsaB2v8E2THDunpp6WBA8M/x5086/QLSvVXLtQKuif0gG/eLP3Cl8G2RU617mr7sP7JaBm8+jkvqNo3d7BfllKkooCOu3ByV/Y92ofv6mUsM0Uu5wkN4QP3Cyr+awk2vFfyp6Trdigzw0xpGF4iVQQfcpSg1viDNJKXNJuBeoNhas0WdWOlnmKcSlgSNtprBNOVwy6V00778J06sVaLcTqUakAvMdLt5D2Pqa7B301IKvHCwroDFGNeWJQO2sDlegx+tKQOa/zjZMkSafz4utE4LVs6IZu//7301VdyJqSuh7/ys8+kEt+87sOGOSMk33/feV+OOkra0TM4YuIDjlYH1qktm9SVlXXeu+4sV2cTfg7VTBS/T/pSJoUYy2iGvkan8mLSdbmZ+zSZsXqJkfqUwXqQG+vsE/wVFX/FGq6iONz3teGX3jnLgnaYy0FB2z/hCG2ibdjy19BZX9Nf+WzTUXykb9hfJ/OqQOrP13qPYyIrZ4w7C13EfcJF+yRycwsKaueuyMpyyrKkBWv8Y+D1Oq1xfyPGGKfT9rbbpHfflSorwxxUD3/lccdJXbs6I35raqSvf/eK2pot6ssClfc4yHlJfJXKZMYqmyoVs0T7sijthjseGcskPcqVGaNvOzbqDP6tzxgU8EXhdbfdzt1aT60RvJdbI5aVE1ARBLbui1nq/n6Y6zSNc9WBdWH3BWkwn+hcpqkoa4X7DK2lk4bxRtB+j3CNBPJi1C2k4v8zYyTQNM5117Vmix7On6CqnCidrsbUGuJEQy3r20kMtuWfRqzxj0FNjePXv+wyJzyzvDw159m0yZf4StLyR/6j7malurHSmeDa95LsvuwqXdP6LwKpLwsiRKVEbynnsrPRDOyRfKTpjNA8DtBbnBDUge2XXiyN2cJvETBwLZYPPccXERWuhd0uJMInL2BA1HjuVwEVas0WDeIz55azTdfxBy2nh7wYHcycsOesdcN4dSWPhbdxbNO93BYUqRVYEYDT0fsgNwmcIIIZM6TOrFEeO/QU47SNfDe52jU84roBpzMiqJyXOUUC/Y5f61ImaTVdnQcrsFFSWOhIQydLLy0N7vSqj1iff1qwxj/D2LhR6p+zSG3YrK840H1BNtJOQ/M+FASPDaiVaFM8epUfEvMNco1csiWXSrVhk2JFu+SwSx6qNZBZyqZKBq/Gc79e4HR3n/Xs5XaIlvC9z2iHjmL2qh3l6sCPyqVSub7OzER0NnhVyDq19o/LYLaG8Zo87FYWu3QEH9c5pi/zg5bP5RkJ1JvvdTBfBrmwQuVWJqoaj87n72G3Dxni/O3HfH1Nf3dDNR7dxIMC6RReVgUFEug79lE/nz4Grx7m+trggESNayKhlpEqilatood3Bt18O3grHVjjn0Hs3Cn99KeOUXyXY92XYyF9tC/fKoddGjAg9N2J1tL3ai82aAK/CVp/NO+nZD7gLHarN4t1Oi/q8n4f6I7siXqcK+oYTn9o4Ro6awhOhdaeDWrDZmVTpae5yN13NgPdL5wLcb56sqkKq38RP6gdG/UKI+SvDFuwQz1Ypt4sdvc7iLmCGrVhk4bxug5gnvZiQ9wdt37Zm8XqywLHNrJNV/KYBOrDQp3Dv/R7X1/BLA5x9fVHLPnTIXsxOogvBdIwXld3VgSd4x2OqxPhJdATXC4P1RrAF058Ps5o8rN4zt3tMp5UVcs29XOrxOu6jGbQ65nw0NI4WOOfIVRXO+kdQJrW4Wr3xXidk9SWTerEWk3Za7xGDV6qArPdZ0gCjVVtJeD3QR/KZypllGvU9mVRXKGH8ciFPO3+zmeb7uTO4DS/vs68W9rUukEKqNDnbY4PKmgXObqMJwSOC+g43gk6z74sUj7b1IbNymO7DN6wht8/kvpFTlU3Vrj34++cr5t4UFnslsGrh7heBq9asVWr6VLnwsppp2c4VyNDctdHk6t5RFns1m3cK4EOYJ5+zgs6ko/1E+boPm4WSPfwfyqnvWbmHRtUwEba6hymqYxeqgGdx1QVst4doduXBXqIG7SODkHHvcZwtWKrurNCX3KwBKopaKX72v3OvUcnHrBamzal6KGNloohkovIDt7KGKzxzwBqaqRrnD48PfywpNJS1bTM10PcIA/V6sZK9fF1lOawM2h0aqAx97DbF9Ypncs0Xc5jivVlUB/D73dVZLFbl/FkWCNaAxqV9ay7qhsr9APFYQtczN5ueSV8r6KAjlLwqoAKdeBHGbxBfRahbqtbmBi0zuDVJtrqLm4XOFE1/pb3BH4T8QIrKNB1/MGtVO5nvO7lNg3jjTopEwYyS+9wrEC6n19JoJ8wRwOZLXAqYINXo3hGNR5fdEucfvKttNIULtERfOL73+/SmTyv1xju+vu/4kD1YLkKqNB0RrgulBkzpPbtnaL6dtusJd2GJH/AVCSXj7/VHw47eCtjsMY/3ZSW6v52vxVIN7aeLJWWqqJCOr7f6iDjPqhkvca1KlUvygRSLjuDBj0N4w0dwDwZvBrNP9WZ1RENf7yt/30DRpXexIN6knECqQurNJKX9A37hz1wC61d4wfSAL6o02oNlFf4mUCazJg6OYz6BfjVA339F/DXoP1y2emeM5tdasMmHcA8CVzXEjh5bUD6gKMdN0RBQZAuMzjRrXyu4HFtoXXQ9iqy9T8O0/38Sj/jFbVlk87keYE0iUsl0OHMDNJtEJ9rh6cguKM1nn9AgCygr27k924ncQ+W63bu1lKKtIquGshseajWo+1vdx+tJUukgwudZG0dWKePOdIpL1mt7Wh5+S0ZjzX+6aS0VP/MvUTg5Fb5mv66PGuycrKq3Xf0xhulxx+XDjlEPsO7Omgw0CHM0pOMUzdWKpfKmAngstjtxtRHkmN4zzWAlzJJ5ThNyPE8oBbslJfIL/0sDgmKYhnOq9pG9I6/BxgvkDbSTh9wdIhRrxTUBFV0PVnmc+04y7XRQDWuy6uACo3jKX3MEQFG+DPdwEPKpVI7aeF0Svo2ltNeF/oqlP1YpA8ZEpdRrvEZZpD+xTl1KpuurHJ98smQXeToec7UcF6TwSuDV0N5U1O4RCfxukC67jrHjajSUm0nX7+g1L2XpfhGESbDz24TsDVprPFPI292Gq1sqpTFbh3s6/SDGmVRrZtvll57TRo82PlP9Ogh9WGh+371okxTOU9TGRUm+iWy5LE9alKzoUOdv/2Yr484KmjjabyofswPe6AXo4e4IajT9EL+qiqyw58oq3Zk6SVMUWfWSKD7+JUgcnK1M/i37uBO1X7V1KiACjfEE6RD+Z9A+gsXqgur3f3u4C4dzkwdxUdBxvs5zlIn1rp++52EmU4tinzKYIH0OidJoKP4yN38OYMabPAjyTJ66m5udyvqtmxyff2nnipV9OzrXuPDXO/+b27nbtWQhAgb68Nv0ljjnybmzZObv8cx5kuVS6W6sVJ/5Dr99Kdyjf6wYbW2si2bdD+/0k5a6F5ui2ofAt3lwMCyAAAR0klEQVQ7x/CeHuQmlQREvQTKID5Xa7NVeezQb7klbFrf/nytkbxUZ/06OmgE04NW38rEsFEqAmeIf4C75Ug+1jG8J+Xnq6fPrfUEl4epuHbIi9HDXBewvkb9mK+WAb54fyjkAJ+LZxhvqCfLdCbPK5sq3cJvJdBKuuk03wjhgcx2O00TldcYLpBmcrhqwN00ngdSZvgDxYvRmwzVuUwLGnk8kNlBeXve5Vj3q+zc/JfdcSUNwvrwmyzW+KeJJ5+UOnrW60oe1TieFDif5QfylUDqmrVWlzBF3TxOyzU7y6tr+aM76nQjbYMqD79kU6lWbFVbNquk9Trd6blHSyjR1/RXF1aHdfn4z3kSr+t7wg4ikBejPHboJh4MWv8ex6gbKwPK9epPXB22jHBSA2pPuS5r8Ve9Ov5dgRPd4rTeg/ss/sYFEujEgBGvJzNdJ/JG0DiGA5nr6tOF1dqNR8fwnvuF9AojNIlLfRFEO/QA4+vmuElA/KNpv2F/Pcz17qaIlV8KZQN76RGu1YG+ISJn8O+g7cvoqUOYJZAG77NOa9em8CG3FUNGY41/Gtk2ZZrOynoh6P3tyI/6ted+Hc9b7rozs/6j71oe5BrLZxilzqwJOq4Lq90RnQavPm1zkrvxUwa7g5cCpQ8L5aFanVmjaZwb1Vgtp4dAepLLJJyEYHdwlwxeV5dcKvUcZyVkrNbRQSD9xvyfOhmnVVrCkjqGv48vxfF5Pv81OOkQ/sFogTSUN2Xw6qCc4FTIb7Y+QwJd7AtNNXh1lM8nfyzvajF7N9jgPuXrCH+ai+WhWofxP33Lvsk17GE6pyNKUZFqaqQ5v3lV3+UdWGf7DvJ0kW/MRFGHCn39dQoebusSynis8U8Ty5YpaMDWXmzQ3W1/r/F5f3L914czszZCA/Q9vevkeenLAj3NxaokVx9xlAxeXccf3B3eYFjYwUvdWCmDV5fzhDbRNqZBedcXzvgWJ2gF3fVT3hfIDUNsw+aggWnxyocMiWjw/XInd2onLXQ6wRXlAvZXIet1CJ+rJdt1Fs+pv+8rBpyEe/488nf7wj0NXrVhsyYzNmrHdSLij+NvyXYN4IuYHdz1klgTooTu68ff+g7Zpwb0OFcomyq1bi29/nqSH3DbGZzxWOOfBj75ROrkm6WxTRtncpdnnql9X0pYomc5222J7yJHE7k1qGP3p7yvV/iZa8B20kJ9WKhifnCH/E9lVJ13z99KP5Cv9CmD4zY+kxkrkB7lKu3FBhVQoYuZInAiWuYedmn8xilAJnGpu+jvowisrI7jHVXj0dscXyfH/QheUS6VGsVUZVOlfXyjoP3bb7rJud9ftj1GxSxx720yo28EupWJ7r11czElW+LNnhkpVUKEsMyPGKLOnZ3Z5R59NIkPuZ2HN+Oxxj8WKfBb7r23E2U4YYI0Z4404mAnD017yvWwuVGV1A4A+pAhbqy7h2qdxXP6jEPrvFS3ca9AehMnXOd+xiu0JV1AhVqyXQ8wPnIUTgT5Ffe7iwP4QvcwQeC4jpZSVJue13+vosWAB8gNPCSonamsNjpH6sRaraaLnmKcstgdMvjLkVP5r9N6ZYtas0XnHfGDayvz8pzBc1ker9pTLpBe4PRaI5Qkw3wz9ymXyoQq04TEn4Atkf0DXUTRxhYUFWnlytqosquvdqYjbTC25Z/xWOMfjRT5LRctktavl154wZm0JZdK3cjv3Xh6v3xNf4HjTrgq+6nwnbEFBfqy68nKYrcuNn9RDbgzf3mo1lgmqRNOXv8RTNdST+9aI52AATqPqQLpWv7oJl47nJlBaY/dexNtyr4QOZPn1Yqt+pZ9dL2vIvDL65yka/mjq/upvCRwQkg7sSYgK2eN2lOuWW1P0NFHOxXrl19KbX3erIsuksqfek5zuoxwQhz9Oenr8aUSTjbRVovYLyllhZV6/L/qSHZ21IlUKiudzLXgG2XeUKzPP+Oxxj8aKW69PPecdGmrqVpCSd1zZGWpkhaa2uEarX/y+Ygtv91k6ydF5erCGm2gvdsn4PeBe6hWV1bpec5UTcuQly8BgzKPA9yJQKYzQlfxaHjfdlFRQuV+xYGahTOC7R+c77bur+ZP7qClG3hIq+jiJnQ7l2fkoVq/5wblslPt2Khv6CuVlmrixNpL/Pxz6cMPo/wD4k081piSmxt5SsSGpk4uLIz5FfvWW9Ly5Ul5vG20T4ZjjX80GsNvGe85IhjU3+XfLXAyZfojYlqwU51YI4NXV/MnbaaNs39BQXAO90Rbv1lxhEMm4PIJlYX0UQEV6s4K7cciZVOlyYyVqB0FfIIvCmoAXyifbdqH7xy3k7/iCTQ0obNSFRZGN0DhWqu5ufFdd6olGZWT9bdbArDGPxqN4beM9xxhkoEtYj+1YKeO5GPtFTJqdwBfhO0bCJLASbYDjXu4eVzz86UTTohtYPytywQN0w7y3PEG4EQ/+b80akD7+RLb9WCZu89BzNUaOtcatsAyc3LCG+3c3NgVQLhKxH9NHk/C15YxYv3tlgBSZvyBB4FFwDzgRaBdwLZbge+Bb4GTAtYP9637HrglnvM0RZ9/nRmV4p3UOqDl58W4OWQCR/IWUKGHuCH+QUuRDEI4IxiPUc/NrZc/fVyLv7mL+/NNbfx9QYE+zD5OIDdjKUhH8nFcIapJM4KRvgqS2HGs/PzorftI5yosjH2/Y1V6lmZHKo3/MCDb9/t+4H7f737AV0ALoARYAmT5ZAnQG8j17dMv1nmaXLRPJCMSaUq9QAJe/se5os77PZKX6hdqGK/e8ZYXOEF34N8IMi33l+7isLwPtIl2Qffhl0OcME1/creTeL3hsfSJThxenw7X0KkSY1VI/q+MaIY8XH9A4NeJv0ERGu1jDb8lhEZx+wA/B6b6ft8K3BqwbQZwhE9mBKwP2i+SNLk4/4a4knzHLqNnUF75LqzSi5xWPyMYLfe6n0QGGCUoi9lbrfOcVAzhwgw3bZJatqxNwHk2z4bNO5TyCiDRssP9PxNx8cUq23aiWhpIYxn/V4Dzfb8f8//2LT8NnOWTKQHrLwAei1DeOGA2MLtXr16pvkfJpSGdyD4jXDs3rFfX8MfgGbTqI7EqnoaGGUaRkfxXWVlO2upwTJtWu/vYYxe7k5gkRbKy4v+/Rfp68Xjidw0mY25c67e3JIkGGX/gbWB+GDktYJ8JPp+/UZKMf6A0q5a/JJWWaqbnSN3BnZrDT5JjBGNVPMn0a4fIOxynmTMjn3rNGumxx6R//MOZ8Szp4ZjxEq2MRFyD8e5r4+QtKSalLX/gImAmkB+wrnm7fa64IrLfNl7q64aJFKlS35Z/MkIgAzuT4zWe4YxitMnBI+mZSMs/0j2II3a+3tg4eUsKSWWH73DgG6BjyPr+IR2+P/g6e7N9v0sCOnz7xzpPkzL+4QyXMYl3PvrLCuzgC43fD2cMc3LqDhSKp+KJZHAbOko2UhmxdIoUjhmpnEghqieckNj9Di2/vvfTYskAUmn8vwdWAHN98lTAtgm+yJ5vgZMD1o8AvvNtmxDPeZqU8W9MP26yW6qRWqGh6wPz+4Quh1ZS0cJH6xuOGU7HZJ0j3hHB1i9vaQI0SodvKqVJGf9ovvNktxZTNTo52a6IhkwCHqvi8euWqnthM1damjDRjL8HS3Lp1SvytnHjYOrU1J8rmg6xmDrV0XPZMsfMLVvWcL0j6WNM9HLD6fLkk+F1S8W9iHZ8Q8u1WNJNpFohk6RJtfxjddQm012QimiRVLitSksjt6CjlRtv+Kn/CyBVI7VtRI6liYJ1+zQy0QbwJNtd0FgumobqXZ/7EW/4qb+MVEXO2IgcSxMlmvG3bp9UMHo0FBWF35aou2DqVCguBo/H+RvqJhk9GsrKoKbG+Tt6dO0xxtRKdjZceWXs8lLl5oh0PzyexHUJxb9fuHsRjVj3wr/PhAmwfLlznokTnfWxjmsM4tHfYolEpFohk6TJtfyl5LgL6lNGLLdTaDx8aHmN6T4JlXh0iXVMQ/SJ5/y5ufEn6Usl1h1liQOs2ydNNNRdUB//e33SNITLO5Nq90mkQVmxdIkU7ZMo8dzbRO5lY4d+2tQQljiIZvz96RgymkGDBmn27NnpVqPx8XicVzoUYxzXRiLHRCNaeamiPtfW2OdP5F429j1M9/2zNAmMMXMkDQq3zfr8M5n6+N/r45tPR9hiukMo4zl/Iro09j1M9/2zNHms8c9kJk6E/Pzgdfn5tZ2O8R4TSFZWYuWlivpcW2OfP9w+ubmQkxP9uMYg3ffP0vSJ5A/KJGmyPv9kUB//e7iUCllZjr88k8IW061LPOePNuVjuu9hpuhhyViwPn+LxWJpflifv8VisViCsMbfYrFYmiHW+KeTTBqhmSpdUnmNmXT/mgr2nln8ROoMyCTZIzt8o43QLC0NziNfWJjazrxUjuoNnQglN7fuKNr6XKsd4Zo49p41O7AdvhlIcbGTkjiUwkKoqICqquD1OTnw17/GzleTTF2KipwcOfWlQwcoL6+7vrAQNmxwWp2XXFK/a02Vznsy9p41O6J1+Frjny7qMxI3VS9pqkaLGhN5mxTZGEHsa7UjXBPH3rNmh432yUTqMxJz+fLk6wHpGy0a7XpiXasd4Zo49p5ZArDGP11EGqFZWBj5mFS9pKkaLRrpWvzrG5Kmwo5wTRx7zyyBROoMyCTZIzt8pcijR0M7ScFJI5zqTt9kjxYtLa2b/jjwOhp6rXaEa+LYe9aswKZ0bmI0drRPKollbPaka7VYMoxoxt92+FosFsseiu3wtVgsFksQ1vhbLBZLM8Qaf4vFYmmGWONvsVgszRBr/C0Wi6UZ0iSifYwx64EIeQCSSgdgQyOcJxk0FV2tnsnF6pl8moqu9dGzSFLHcBuahPFvLIwxsyOFRWUaTUVXq2dysXomn6aia7L1tG4fi8ViaYZY42+xWCzNEGv8g5mcbgUSoKnoavVMLlbP5NNUdE2qntbnb7FYLM0Q2/K3WCyWZog1/haLxdIMscY/BGPMb4wx84wxc40xbxpjuqVbp3AYYx40xizy6fqiMaZdunUKhzHmbGPMAmNMjTEm48LpjDHDjTHfGmO+N8bckm59ImGM+YsxZp0xZn66dYmGMaanMeY9Y8w3vv/7denWKRzGmDxjzOfGmK98et6dbp2iYYzJMsZ8aYyZnqwyrfGvy4OSDpI0AJgO3JFuhSLwFnCApIOA74Bb06xPJOYDZwAfpluRUIwxWcDjwMlAP+A8Y0y/9GoVkb8Bw9OtRBxUAzdJ6gcMBq7K0Hu6Czhe0sHAAGC4MWZwmnWKxnXAwmQWaI1/CJK2BiwWABnZIy7pTUnVvsX/AT3SqU8kJC2U9G269YjAYcD3kn6QVAX8CzgtzTqFRdKHwMZ06xELSWskfeH7XYFjsLqnV6u6+OY62eZbzPFJRr7rxpgewM+AKcks1xr/MBhjJhpjVgCjydyWfyCXAK+nW4kmSHdgRcDySjLQUDVVjDHFwE+Az9KrSXh8rpS5wDrgLUkZqSfwR+BmoCaZhTZL42+MedsYMz+MnAYgaYKknsBU4OpM1dO3zwScT+2pmaynpXlhjGkFvABcH/I1nTFI8vrcuz2Aw4wxB6Rbp1CMMacA6yTNSXbZ2ckusCkgaWicu04FXgPuTKE6EYmlpzHmIuAU4ASlccBGAvcz01gF9AxY7uFbZ2kAxpgcHMM/VdJ/0q1PLCRtNsa8h9Onkmkd6kcBI40xI4A8oI0xplTS+Q0tuFm2/KNhjNk3YPE0YFG6dImGMWY4zqfgSEk70q1PE2UWsK8xpsQYkwuMAl5Os05NGmOMAZ4GFkp6ON36RMIY09EfIWeMaQmcSAa+65JuldRDUjHO8/luMgw/WOMfjvt8Lot5wDCcXvZM5DGgNfCWLyz1qXQrFA5jzM+NMSuBI4BXjTEz0q2TH1+H+dXADJyOyeckLUivVuExxkwDZgJ9jDErjTFj0q1TBI4CLgCO9z2Xc32t1kyjK/Ce7z2fhePzT1oYZVPApnewWCyWZoht+VssFkszxBp/i8ViaYZY42+xWCzNEGv8LRaLpRlijb/FYrE0Q6zxt1gslmaINf4Wi8XSDPl/nP9xmpClJgMAAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.normal(0, 100, (2, 1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eHDT6FFgX9EA",
        "outputId": "094da2ed-89e1-4a03-95a5-e47593286947"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 95.5811],\n",
              "        [-58.3666]])"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.rand(4, 3,requires_grad=True)"
      ],
      "metadata": {
        "id": "4Yx4f3-ikJvU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "  a.shape[1]\n",
        "except:\n",
        "  a = a.reshape(-1, 1)"
      ],
      "metadata": {
        "id": "fNZ5rNQakNrP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rikfUp1LkndW",
        "outputId": "43fa4db8-76d1-4993-977d-7bc904488ab8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.8787, 0.3696, 0.2905],\n",
              "        [0.6539, 0.8666, 0.2512],\n",
              "        [0.7758, 0.4490, 0.4571],\n",
              "        [0.2726, 0.2643, 0.1135]], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def give_data(n_samples, w, b, noise=0.01):\n",
        "\n",
        "  try:\n",
        "    w.shape[1]\n",
        "  except:\n",
        "    w = w.reshape(-1, 1)\n",
        "    \n",
        "  X = torch.randn(n_samples, len(w))\n",
        "  noise = torch.randn(n_samples, 1) * noise\n",
        "  y = torch.mm(X, w) + b + noise\n",
        "  return X, y"
      ],
      "metadata": {
        "id": "V3GFEkVGbK4o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LinearRegression():\n",
        "\n",
        "  def __init__(self, input_size, output_size, lr=0.01, std=0.01):\n",
        "    self.input_size = input_size\n",
        "    self.output_size = output_size\n",
        "    self.lr = lr\n",
        "    # self.w = torch.normal(0, std, (input_size, 1), requires_grad=True, dtype=torch.float32)\n",
        "    self.w = torch.zeros(input_size, 1, requires_grad=True, dtype=torch.float32)\n",
        "    self.b = torch.zeros(1, requires_grad=True, dtype=torch.float32)\n",
        "\n",
        "  def forward(self, X):\n",
        "    y_hat = torch.mm(X, self.w) + self.b\n",
        "    return y_hat\n",
        "\n",
        "  def loss(self, y_hat, y):\n",
        "    crit = nn.MSELoss()\n",
        "    return crit(y_hat, y)"
      ],
      "metadata": {
        "id": "jfB6g7ETYxpw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Optim(): \n",
        "\n",
        "  def __init__(self, params, lr):\n",
        "    self.params = params\n",
        "    self.lr = lr\n",
        "\n",
        "  def update(self):\n",
        "    with torch.no_grad():\n",
        "      for param in self.params:\n",
        "        param -= self.lr * param.grad\n",
        "\n",
        "  def empty_grad(self):\n",
        "    for param in self.params:\n",
        "      param.grad.zero_()"
      ],
      "metadata": {
        "id": "IOJtH0HalW_D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Trainer():\n",
        "\n",
        "  def __init__(self, model, X, y):\n",
        "    self.model = model\n",
        "    self.X = X\n",
        "    self.y = y\n",
        "    self.optimizer = Optim([model.w, model.b], model.lr)\n",
        "\n",
        "  def train_model(self, max_epochs=100):\n",
        "\n",
        "    for epoch in range(max_epochs):\n",
        "\n",
        "      # forward_pass:\n",
        "      y_hat = self.model.forward(self.X)\n",
        "      l = self.model.loss(self.y, y_hat)\n",
        "\n",
        "      # backward_pass:\n",
        "      l.backward(retain_graph=True)\n",
        "\n",
        "      # update the params:\n",
        "      self.optimizer.update()\n",
        "\n",
        "      # empty the grad:\n",
        "      self.optimizer.empty_grad()\n",
        "\n",
        "      if (epoch+1) % (max_epochs/10) == 0:\n",
        "        print(f\"epoch : {epoch+1}/{max_epochs}, w = {self.model.w[0][0].item():.3f} & {self.model.w[1][0].item():.3f}, b = {self.model.b.item():.3f}, loss = {l:.4f}\")"
      ],
      "metadata": {
        "id": "FLRmzw7wg0nZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w = torch.tensor([1.0, -2.5], dtype=torch.float32).reshape(-1, 1)\n",
        "b = torch.tensor(-4.6, dtype=torch.float32)\n",
        "\n",
        "X, y = give_data(1000, w, b)"
      ],
      "metadata": {
        "id": "qvb9hM7CcwXe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X.shape, y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jDhzMh9XfSbw",
        "outputId": "6b4ae53c-3f54-40c2-9517-403fb904efaf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1000, 2]) torch.Size([1000, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = LinearRegression(X.shape[1], y.shape[1])\n",
        "optimizer = Optim([model.w, model.b], model.lr)\n",
        "\n",
        "max_epochs = 1000\n",
        "\n",
        "for epoch in range(max_epochs):\n",
        "\n",
        "  # forward pass\n",
        "  y_hat = model.forward(X)\n",
        "  l = model.loss(y_hat, y)\n",
        "\n",
        "  # backward pass\n",
        "  l.backward(retain_graph=True)\n",
        "\n",
        "  # update the params\n",
        "  optimizer.update()\n",
        "\n",
        "  # zero the grad\n",
        "  optimizer.empty_grad()\n",
        "\n",
        "  if (epoch+1)%100 == 0:\n",
        "    print(f\"epoch : {epoch+1}/{max_epochs}, w = {model.w[0][0].item():.3f} & {model.w[1][0].item():.3f}, b = {model.b.item():.3f}, loss = {l:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "id": "i8ZQx6nrfY21",
        "outputId": "8ad312bf-0dcd-46d6-eb75-51acf47b8cd2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-c0c443a57573>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLinearRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOptim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmax_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'LinearRegression' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w = torch.tensor([-5.9, 3.2], dtype=torch.float32, requires_grad=True)\n",
        "b = torch.tensor([-9.4], dtype=torch.float32, requires_grad=True)\n",
        "\n",
        "X, y = give_data(1000, w, b)\n",
        "model = LinearRegression(X.shape[1], y.shape[1])\n",
        "trainer = Trainer(model, X, y)"
      ],
      "metadata": {
        "id": "I8xT6CvDhyny"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train_model(1000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XNMoJVdkjfBh",
        "outputId": "6e5322a4-2866-4564-ad03-fda68c64fd74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch : 100/1000, w = -4.829 & 2.730, b = -8.061, loss = 3.0228\n",
            "epoch : 200/1000, w = -5.709 & 3.133, b = -9.207, loss = 0.0743\n",
            "epoch : 300/1000, w = -5.867 & 3.190, b = -9.372, loss = 0.0020\n",
            "epoch : 400/1000, w = -5.895 & 3.198, b = -9.396, loss = 0.0002\n",
            "epoch : 500/1000, w = -5.900 & 3.199, b = -9.399, loss = 0.0001\n",
            "epoch : 600/1000, w = -5.901 & 3.199, b = -9.400, loss = 0.0001\n",
            "epoch : 700/1000, w = -5.901 & 3.199, b = -9.400, loss = 0.0001\n",
            "epoch : 800/1000, w = -5.901 & 3.199, b = -9.400, loss = 0.0001\n",
            "epoch : 900/1000, w = -5.901 & 3.199, b = -9.400, loss = 0.0001\n",
            "epoch : 1000/1000, w = -5.901 & 3.199, b = -9.400, loss = 0.0001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = torch.randn(1000, 5)\n",
        "w = torch.tensor([1.4, 6.7, -4.5, -3.2, 8.5], dtype=torch.float32).reshape(-1, 1)\n",
        "b = torch.tensor([-9.54], dtype=torch.float32)\n",
        "\n",
        "y = torch.mm(X, w) + b\n",
        "max_epochs = 100\n",
        "crit = nn.MSELoss()\n",
        "\n",
        "w = torch.randn(5, 1, requires_grad=True)\n",
        "b = torch.randn(1, requires_grad=True)\n",
        "\n",
        "for epoch in range(max_epochs):\n",
        "  y_hat = torch.mm(X, w) + b\n",
        "  l = crit(y, y_hat)\n",
        "  l.backward()\n",
        "\n",
        "  with torch.no_grad():\n",
        "    w -= 0.01 * w.grad\n",
        "    b -= 0.01 * b.grad\n",
        "\n",
        "  w.grad.zero_()\n",
        "  b.grad.zero_()\n",
        "\n",
        "  if (epoch+1)%10 == 0:\n",
        "    print(f\"epoch : {epoch+1}/{max_epochs}, w = {w}, b = {b}, loss = {l}\")\n"
      ],
      "metadata": {
        "id": "IO4sRhg5lpPC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dea55027-7e68-442a-cf0a-a9b1bae91c2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch : 10/100, w = tensor([[0.7183],\n",
            "        [1.5214],\n",
            "        [0.9248],\n",
            "        [0.6431],\n",
            "        [2.2365]], requires_grad=True), b = tensor([-0.6587], requires_grad=True), loss = 197.0800323486328\n",
            "epoch : 20/100, w = tensor([[ 0.8292],\n",
            "        [ 2.4711],\n",
            "        [-0.0373],\n",
            "        [ 0.0468],\n",
            "        [ 3.4258]], requires_grad=True), b = tensor([-2.3099], requires_grad=True), loss = 131.53370666503906\n",
            "epoch : 30/100, w = tensor([[ 0.9220],\n",
            "        [ 3.2463],\n",
            "        [-0.8281],\n",
            "        [-0.4590],\n",
            "        [ 4.3901]], requires_grad=True), b = tensor([-3.6534], requires_grad=True), loss = 87.82720947265625\n",
            "epoch : 40/100, w = tensor([[ 0.9997],\n",
            "        [ 3.8790],\n",
            "        [-1.4781],\n",
            "        [-0.8875],\n",
            "        [ 5.1718]], requires_grad=True), b = tensor([-4.7466], requires_grad=True), loss = 58.67092514038086\n",
            "epoch : 50/100, w = tensor([[ 1.0647],\n",
            "        [ 4.3956],\n",
            "        [-2.0126],\n",
            "        [-1.2503],\n",
            "        [ 5.8053]], requires_grad=True), b = tensor([-5.6364], requires_grad=True), loss = 39.21233367919922\n",
            "epoch : 60/100, w = tensor([[ 1.1191],\n",
            "        [ 4.8173],\n",
            "        [-2.4521],\n",
            "        [-1.5571],\n",
            "        [ 6.3187]], requires_grad=True), b = tensor([-6.3606], requires_grad=True), loss = 26.219970703125\n",
            "epoch : 70/100, w = tensor([[ 1.1647],\n",
            "        [ 5.1617],\n",
            "        [-2.8136],\n",
            "        [-1.8164],\n",
            "        [ 6.7347]], requires_grad=True), b = tensor([-6.9501], requires_grad=True), loss = 17.541051864624023\n",
            "epoch : 80/100, w = tensor([[ 1.2028],\n",
            "        [ 5.4429],\n",
            "        [-3.1111],\n",
            "        [-2.0354],\n",
            "        [ 7.0716]], requires_grad=True), b = tensor([-7.4300], requires_grad=True), loss = 11.740774154663086\n",
            "epoch : 90/100, w = tensor([[ 1.2347],\n",
            "        [ 5.6726],\n",
            "        [-3.3558],\n",
            "        [-2.2203],\n",
            "        [ 7.3446]], requires_grad=True), b = tensor([-7.8208], requires_grad=True), loss = 7.862475872039795\n",
            "epoch : 100/100, w = tensor([[ 1.2615],\n",
            "        [ 5.8602],\n",
            "        [-3.5573],\n",
            "        [-2.3761],\n",
            "        [ 7.5656]], requires_grad=True), b = tensor([-8.1390], requires_grad=True), loss = 5.2680134773254395\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.randn(5, 1, requires_grad=True)\n",
        "print(f\"a = {a}\")\n",
        "\n",
        "for i in range(5):\n",
        "  b = (2*a).sum()\n",
        "  b.backward()\n",
        "  print(f\"iter = {i+1}, a.grad = {a.grad}\")\n",
        "  a.grad.zero_()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X1WF-7bbx9ok",
        "outputId": "bf196290-c72e-4f4c-8f5d-d46f443cd425"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a = tensor([[-1.5663],\n",
            "        [-0.5506],\n",
            "        [-0.1211],\n",
            "        [-1.2993],\n",
            "        [-2.6648]], requires_grad=True)\n",
            "iter = 1, a.grad = tensor([[2.],\n",
            "        [2.],\n",
            "        [2.],\n",
            "        [2.],\n",
            "        [2.]])\n",
            "iter = 2, a.grad = tensor([[2.],\n",
            "        [2.],\n",
            "        [2.],\n",
            "        [2.],\n",
            "        [2.]])\n",
            "iter = 3, a.grad = tensor([[2.],\n",
            "        [2.],\n",
            "        [2.],\n",
            "        [2.],\n",
            "        [2.]])\n",
            "iter = 4, a.grad = tensor([[2.],\n",
            "        [2.],\n",
            "        [2.],\n",
            "        [2.],\n",
            "        [2.]])\n",
            "iter = 5, a.grad = tensor([[2.],\n",
            "        [2.],\n",
            "        [2.],\n",
            "        [2.],\n",
            "        [2.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.randn(10, 5, requires_grad=True)\n",
        "b = 5 * a\n",
        "b = b.sum()\n",
        "b.backward(retain_graph=True)\n",
        "print(f\"a.grad = {a.grad}\")\n",
        "a.grad.zero_()\n",
        "b.backward(retain_graph=True)\n",
        "print(f\"a.grad = {a.grad}\")\n",
        "b.backward()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zCY2tIm4yiJR",
        "outputId": "e27e8e47-8a9a-4745-85fa-2083beed9c19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a.grad = tensor([[5., 5., 5., 5., 5.],\n",
            "        [5., 5., 5., 5., 5.],\n",
            "        [5., 5., 5., 5., 5.],\n",
            "        [5., 5., 5., 5., 5.],\n",
            "        [5., 5., 5., 5., 5.],\n",
            "        [5., 5., 5., 5., 5.],\n",
            "        [5., 5., 5., 5., 5.],\n",
            "        [5., 5., 5., 5., 5.],\n",
            "        [5., 5., 5., 5., 5.],\n",
            "        [5., 5., 5., 5., 5.]])\n",
            "a.grad = tensor([[5., 5., 5., 5., 5.],\n",
            "        [5., 5., 5., 5., 5.],\n",
            "        [5., 5., 5., 5., 5.],\n",
            "        [5., 5., 5., 5., 5.],\n",
            "        [5., 5., 5., 5., 5.],\n",
            "        [5., 5., 5., 5., 5.],\n",
            "        [5., 5., 5., 5., 5.],\n",
            "        [5., 5., 5., 5., 5.],\n",
            "        [5., 5., 5., 5., 5.],\n",
            "        [5., 5., 5., 5., 5.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Trying again!!"
      ],
      "metadata": {
        "id": "zmAxS4FkzigA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def give_data(n_samples, w, b, noise=0.01):\n",
        "\n",
        "  try:\n",
        "    w.shape[1]\n",
        "  except:\n",
        "    w = w.reshape(-1, 1)\n",
        "    \n",
        "  X = torch.randn(n_samples, len(w))\n",
        "  noise = torch.randn(n_samples, 1) * noise\n",
        "  y = torch.mm(X, w) + b + noise\n",
        "  return X, y"
      ],
      "metadata": {
        "id": "VpZCzg7by0vR"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LinearRegression():\n",
        "\n",
        "  def __init__(self, input_size, output_size, lr=0.01, std=0.01):\n",
        "    self.input_size = input_size\n",
        "    self.output_size = output_size\n",
        "    self.lr = lr\n",
        "    # self.w = torch.normal(0, std, (input_size, 1), requires_grad=True, dtype=torch.float32)\n",
        "    self.w = torch.zeros(input_size, 1, requires_grad=True, dtype=torch.float32)\n",
        "    self.b = torch.zeros(1, requires_grad=True, dtype=torch.float32)\n",
        "\n",
        "  def forward(self, X):\n",
        "    \n",
        "    y_hat = torch.mm(X, self.w) + self.b\n",
        "    return y_hat\n",
        "\n",
        "  def loss(self, y_hat, y):\n",
        "    crit = nn.MSELoss()\n",
        "    return crit(y_hat, y)"
      ],
      "metadata": {
        "id": "T9G3lGoqzs7K"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Optim(): \n",
        "\n",
        "  def __init__(self, params, lr):\n",
        "    self.params = params\n",
        "    self.lr = lr\n",
        "\n",
        "  def update(self):\n",
        "    with torch.no_grad():\n",
        "      for param in self.params:\n",
        "        param -= self.lr * param.grad\n",
        "\n",
        "  def empty_grad(self):\n",
        "    for param in self.params:\n",
        "      param.grad.zero_()"
      ],
      "metadata": {
        "id": "ARXXFoYRzvi2"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Trainer():\n",
        "\n",
        "  def __init__(self, model, X, y):\n",
        "    self.model = model\n",
        "    self.X = X\n",
        "    self.y = y\n",
        "    self.optimizer = Optim([model.w, model.b], model.lr)\n",
        "\n",
        "  def train_model(self, max_epochs=100):\n",
        "\n",
        "    for epoch in range(max_epochs):\n",
        "\n",
        "      # forward_pass:\n",
        "      y_hat = self.model.forward(self.X)\n",
        "      l = self.model.loss(self.y, y_hat)\n",
        "\n",
        "      # backward_pass:\n",
        "      l.backward(retain_graph=True)\n",
        "\n",
        "      # update the params:\n",
        "      self.optimizer.update()\n",
        "\n",
        "      # empty the grad:\n",
        "      self.optimizer.empty_grad()\n",
        "\n",
        "      if (epoch+1) % (max_epochs/10) == 0:\n",
        "        print(f\"epoch : {epoch+1}/{max_epochs}, b = {self.model.b.item():.3f}, loss = {l:.4f}\")"
      ],
      "metadata": {
        "id": "03tOTIAzzxuo"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w = torch.tensor([-4, -6.7], dtype=torch.float32)\n",
        "b = torch.tensor([-5.7], dtype=torch.float32)\n",
        "n_samples = 100\n",
        "\n",
        "X, y = give_data(n_samples, w, b)\n",
        "print(f\"X.shape = {X.shape}\")\n",
        "print(f\"y.shape = {y.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PXlRLQTB0WlD",
        "outputId": "a047e6da-9f6b-4452-a4d4-4f180cfebcdb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X.shape = torch.Size([100, 2])\n",
            "y.shape = torch.Size([100, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = LinearRegression(X.shape[1], y.shape[1])\n",
        "trainer = Trainer(model, X, y)\n",
        "trainer.train_model(max_epochs=1000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ScC_tbpN0_VJ",
        "outputId": "92d0343b-eed0-43a3-9ba4-9d5176560b03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch : 100/1000, w = -3.046 & -5.968, b = -4.859, loss = 1.9866\n",
            "epoch : 200/1000, w = -3.797 & -6.614, b = -5.566, loss = 0.0579\n",
            "epoch : 300/1000, w = -3.958 & -6.689, b = -5.678, loss = 0.0021\n",
            "epoch : 400/1000, w = -3.991 & -6.698, b = -5.696, loss = 0.0002\n",
            "epoch : 500/1000, w = -3.998 & -6.700, b = -5.700, loss = 0.0001\n",
            "epoch : 600/1000, w = -3.999 & -6.700, b = -5.700, loss = 0.0001\n",
            "epoch : 700/1000, w = -3.999 & -6.700, b = -5.700, loss = 0.0001\n",
            "epoch : 800/1000, w = -3.999 & -6.700, b = -5.700, loss = 0.0001\n",
            "epoch : 900/1000, w = -3.999 & -6.700, b = -5.700, loss = 0.0001\n",
            "epoch : 1000/1000, w = -3.999 & -6.700, b = -5.700, loss = 0.0001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class LinearModel():\n",
        "\n",
        "  def __init__(self, input_size, output_size, lr=0.01):\n",
        "    self.lin = nn.Linear(input_size, output_size)\n",
        "\n",
        "  def loss(self, y_hat, y):\n",
        "    crit = nn.MSELoss()\n",
        "    return crit(y_hat, y)"
      ],
      "metadata": {
        "id": "rEl6eG4w2-lu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = LinearModel(5, 1).lin"
      ],
      "metadata": {
        "id": "O5vHeZl330pn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, par in enumerate(model.parameters()):\n",
        "  print(f\"i = {i}, parameter = {par}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CSnkhH094LiL",
        "outputId": "74314592-bfc5-47b1-8ef4-aff426ce457e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "i = 0, parameter = Parameter containing:\n",
            "tensor([[0.0534, 0.2215, 0.0926, 0.2665, 0.2619]], requires_grad=True)\n",
            "i = 1, parameter = Parameter containing:\n",
            "tensor([0.2772], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn.parameter import Parameter"
      ],
      "metadata": {
        "id": "tRsHmYIW6DtR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = Parameter(torch.randn(5, 1, requires_grad=True))"
      ],
      "metadata": {
        "id": "6s7R6gAz5uyE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KaYD0Mcw6MWy",
        "outputId": "1ebb5394-a14c-4cae-812f-54c04d0ad1ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[-0.6138],\n",
              "        [ 0.7925],\n",
              "        [-1.0220],\n",
              "        [ 1.0425],\n",
              "        [ 1.5471]], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = LinearModel(10, 1).lin\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d3TbZ_R46ShT",
        "outputId": "0423b5b4-611d-4350-ec79-8de1ae399e5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Linear(in_features=10, out_features=1, bias=True)"
            ]
          },
          "metadata": {},
          "execution_count": 130
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i, par in enumerate(model.parameters()):\n",
        "\n",
        "  if i == 0:\n",
        "    par = Parameter(torch.zeros(10, 1), requires_grad=True)\n",
        "  else:\n",
        "    par = Parameter(torch.zeros(1, requires_grad=True))\n",
        "\n",
        "for par in model.parameters():\n",
        "  print(par)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DjubHAgb6X5q",
        "outputId": "dba4fd69-f213-41d0-f9a5-997db64891dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter containing:\n",
            "tensor([[ 0.1671,  0.1896,  0.2908, -0.2934, -0.1160,  0.1101, -0.1318,  0.3157,\n",
            "          0.0034,  0.0984]], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0829], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Q2:\n",
        "\n",
        "since V = IR is a linear relationship between y=V and X=I, i think we can find the learn the value of R\n",
        "\n",
        "assuming V is linear with I"
      ],
      "metadata": {
        "id": "gO_IbCVI1lEM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "r = 100 # resitance, let's see if the model can learn it\n",
        "X = torch.randn(1000, 1)\n",
        "y = r * X"
      ],
      "metadata": {
        "id": "0h_bwZn_PxgV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F16r0j7I1XlQ",
        "outputId": "8fadc1a0-9686-42de-f91f-c68afad6ee06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1000, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 149
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate=0.01\n",
        "max_epochs = 1000\n",
        "\n",
        "model = nn.Linear(X.shape[1], y.shape[1])\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)\n",
        "crit = nn.MSELoss()\n",
        "\n",
        "for epoch in range(max_epochs):\n",
        "\n",
        "  # forward pass : y_hat and loss\n",
        "  y_hat = model(X)\n",
        "  l = crit(y_hat, y)\n",
        "\n",
        "  # backward pass : gradient\n",
        "  l.backward()\n",
        "\n",
        "  # update the params\n",
        "  optimizer.step()\n",
        "\n",
        "  # zero the grad\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "  if (epoch+1) % (max_epochs/10) == 0:\n",
        "    print(f\"epoch : {epoch+1}/{max_epochs}, loss = {l}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Jxc9Tl_QK9H",
        "outputId": "2302eb30-d02d-4389-d2e9-8c6ecda21a88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch : 100/1000, loss = 202.58876037597656\n",
            "epoch : 200/1000, loss = 4.0843048095703125\n",
            "epoch : 300/1000, loss = 0.08245765417814255\n",
            "epoch : 400/1000, loss = 0.0016662359703332186\n",
            "epoch : 500/1000, loss = 3.377368557266891e-05\n",
            "epoch : 600/1000, loss = 7.003586688369978e-07\n",
            "epoch : 700/1000, loss = 3.542697513125859e-08\n",
            "epoch : 800/1000, loss = 3.531340198037469e-08\n",
            "epoch : 900/1000, loss = 3.531340198037469e-08\n",
            "epoch : 1000/1000, loss = 3.531340198037469e-08\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for par in model.parameters():\n",
        "  print(par)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PF0V7m62Q87g",
        "outputId": "cd2f4d49-9f5d-4ed4-bf7b-51a3edb9dae4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter containing:\n",
            "tensor([[99.9998]], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([3.7873e-06], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "the model correctly predicted the value of R"
      ],
      "metadata": {
        "id": "S454FXyLUcts"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Q8 : using a different loss function\n",
        "\n",
        "MSELoss performs much better"
      ],
      "metadata": {
        "id": "sncuhm2zVqGA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ],
      "metadata": {
        "id": "t0uWXwnkavma"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ModLinear():\n",
        "\n",
        "  def __init__(self, input_size, output_size, lr=0.01, std=0.01):\n",
        "    self.input_size = input_size\n",
        "    self.output_size = output_size\n",
        "    self.lr = lr\n",
        "    # self.w = torch.normal(0, std, (input_size, 1), requires_grad=True, dtype=torch.float32)\n",
        "    self.w = torch.zeros(input_size, 1, requires_grad=True, dtype=torch.float32)\n",
        "    self.b = torch.zeros(1, requires_grad=True, dtype=torch.float32)\n",
        "\n",
        "  def forward(self, X):\n",
        "    \n",
        "    y_hat = torch.mm(X, self.w) + self.b\n",
        "    return y_hat\n",
        "\n",
        "  def loss(self, y_hat, y):\n",
        "    l = abs(y - y_hat).sum()\n",
        "    return l"
      ],
      "metadata": {
        "id": "O61Jdf6ichU_"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(0)\n",
        "\n",
        "w = torch.tensor([-5.6, 7.8, 3.4, 1.6, -9.], dtype=torch.float32, requires_grad=True).reshape(-1, 1)\n",
        "b = torch.tensor([-8.56], dtype=torch.float32, requires_grad=True)\n",
        "\n",
        "X, y = give_data(1000, w, b)"
      ],
      "metadata": {
        "id": "v4lww80TUa57"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"X.shape = {X.shape}\")\n",
        "print(f\"y.shape = {y.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mjlPB1y6b0Da",
        "outputId": "81277936-2fe0-4f26-cb61-0f935b7e4bb0"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X.shape = torch.Size([1000, 5])\n",
            "y.shape = torch.Size([1000, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model1 = ModLinear(X.shape[1], y.shape[1]) # using different loss function\n",
        "model2 = LinearRegression(X.shape[1], y.shape[1]) # using MSE\n",
        "trainer1 = Trainer(model1, X, y)\n",
        "trainer2 = Trainer(model2, X, y)"
      ],
      "metadata": {
        "id": "f7JZzQqoc4do"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# nn.MSELoss model:\n",
        "trainer2.train_model(1000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fgunyCs9eJzC",
        "outputId": "49ab43ab-cff0-4297-a26c-5e14d1853e80"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch : 100/1000, b = -7.535, loss = 4.7808\n",
            "epoch : 200/1000, b = -8.437, loss = 0.0898\n",
            "epoch : 300/1000, b = -8.546, loss = 0.0019\n",
            "epoch : 400/1000, b = -8.559, loss = 0.0001\n",
            "epoch : 500/1000, b = -8.560, loss = 0.0001\n",
            "epoch : 600/1000, b = -8.560, loss = 0.0001\n",
            "epoch : 700/1000, b = -8.560, loss = 0.0001\n",
            "epoch : 800/1000, b = -8.560, loss = 0.0001\n",
            "epoch : 900/1000, b = -8.560, loss = 0.0001\n",
            "epoch : 1000/1000, b = -8.560, loss = 0.0001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# absolute value loss\n",
        "trainer1.train_model(1000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wU9wWz0jevYu",
        "outputId": "3bbca899-26eb-4ca3-c9da-c4f0a229a964"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch : 100/1000, b = -11.660, loss = 6921.1787\n",
            "epoch : 200/1000, b = -11.660, loss = 6921.1787\n",
            "epoch : 300/1000, b = -11.660, loss = 6921.1787\n",
            "epoch : 400/1000, b = -11.660, loss = 6921.1787\n",
            "epoch : 500/1000, b = -11.660, loss = 6921.1787\n",
            "epoch : 600/1000, b = -11.660, loss = 6921.1787\n",
            "epoch : 700/1000, b = -11.660, loss = 6921.1787\n",
            "epoch : 800/1000, b = -11.660, loss = 6921.1787\n",
            "epoch : 900/1000, b = -11.660, loss = 6921.1787\n",
            "epoch : 1000/1000, b = -11.660, loss = 6921.1787\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.tensor([-1, -2, -3, -4], dtype=torch.float32, requires_grad=True)\n",
        "b = torch.tensor([1, 2, 3, 4], dtype=torch.float32, requires_grad=True) \n",
        "\n",
        "abs(a-b).sum().backward()\n",
        "b.grad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BlmEc3AUZyNZ",
        "outputId": "1ac95abc-8d34-4c1e-f352-3968c1e159a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1., 1., 1., 1.])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = nn.Linear(5, 1)\n",
        "a = torch.randn(1000, 5)\n",
        "(model(a) - a).abs().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hyWiSHFjaIoq",
        "outputId": "c3dc3cd4-8fa3-4b13-89a3-cf3792d84d7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(4428.3755, grad_fn=<SumBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# changing few values : Both the models perform equally badly"
      ],
      "metadata": {
        "id": "n-ZVprLwgqxo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "zvW9caUjg-z-"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(0)\n",
        "\n",
        "w = torch.tensor([-5.6, 7.8, 3.4, 1.6, -9.], dtype=torch.float32, requires_grad=True).reshape(-1, 1)\n",
        "b = torch.tensor([-8.56], dtype=torch.float32, requires_grad=True)\n",
        "\n",
        "X, y = give_data(1000, w, b)"
      ],
      "metadata": {
        "id": "G4hji1S1iQP4"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"y.shape = {y.shape}\")"
      ],
      "metadata": {
        "id": "TvoirXg5Zgq7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86b54591-cbb3-4084-dfc9-ed95557d9b4a"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "y.shape = torch.Size([1000, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "  for i in np.arange(0, 1000, 200):\n",
        "    y[i, 0] = torch.tensor(10000, dtype=torch.float32, requires_grad=True)"
      ],
      "metadata": {
        "id": "bW4zUvjcgxU1"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model1 = ModLinear(X.shape[1], y.shape[1]) # using different loss function\n",
        "model2 = LinearRegression(X.shape[1], y.shape[1]) # using MSE\n",
        "trainer1 = Trainer(model1, X, y)\n",
        "trainer2 = Trainer(model2, X, y)"
      ],
      "metadata": {
        "id": "t1B-7SaPhqsX"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer1.train_model(1000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7q7X_WQIh5V-",
        "outputId": "1a0ed17e-dd80-4553-a1fa-88bbb6c8e3fd"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch : 100/1000, b = -9.340, loss = 59131.9336\n",
            "epoch : 200/1000, b = -9.080, loss = 59387.3438\n",
            "epoch : 300/1000, b = -13.200, loss = 55295.5586\n",
            "epoch : 400/1000, b = -9.020, loss = 59445.6094\n",
            "epoch : 500/1000, b = -11.160, loss = 57290.6133\n",
            "epoch : 600/1000, b = -11.580, loss = 56847.6094\n",
            "epoch : 700/1000, b = -11.240, loss = 57255.4102\n",
            "epoch : 800/1000, b = -10.840, loss = 57633.2969\n",
            "epoch : 900/1000, b = -10.960, loss = 57487.9609\n",
            "epoch : 1000/1000, b = -10.520, loss = 57943.2812\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer2.train_model(1000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FQ5fd8nzh8XZ",
        "outputId": "6106e5d1-98ae-4424-8092-b47c49491c28"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch : 100/1000, b = 36.376, loss = 497635.7500\n",
            "epoch : 200/1000, b = 41.584, loss = 497570.8125\n",
            "epoch : 300/1000, b = 42.346, loss = 497569.1562\n",
            "epoch : 400/1000, b = 42.460, loss = 497569.0938\n",
            "epoch : 500/1000, b = 42.477, loss = 497569.1562\n",
            "epoch : 600/1000, b = 42.479, loss = 497569.0938\n",
            "epoch : 700/1000, b = 42.480, loss = 497569.1562\n",
            "epoch : 800/1000, b = 42.480, loss = 497569.1562\n",
            "epoch : 900/1000, b = 42.480, loss = 497569.1562\n",
            "epoch : 1000/1000, b = 42.480, loss = 497569.1562\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Q10:\n",
        "\n",
        "we shuffle the data to make sure that the model is not overfitting to certain order due to sort order"
      ],
      "metadata": {
        "id": "1JL0YcIDjL6-"
      }
    }
  ]
}